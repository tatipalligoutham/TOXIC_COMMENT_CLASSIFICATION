{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ToxicCommentClassificationFinal.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-1dmwfrcfCi"
      },
      "source": [
        "# <A href=\"https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge\">Toxic Comment Classification</a>\n",
        "Given dataset of wikipedia comments, we are supposed to build a model that can predict the probability that the comments falls under the categories of toxicity (6 categories in this case)\n",
        "\n",
        "This is a supervised learning problem as we are given a dataset and the also if it falls in the toxic category (any one of the classes, or multiple classes)\n",
        "\n",
        "This is a classification problem as we are classifying the dataset into classes. Also, we are supposed to predict the probability that it falls under each classes, so this is also a regression problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pW3nMXlDd2FB"
      },
      "source": [
        "We use three algorithms to train our model\n",
        "* Logistic Regression\n",
        "* Naive Bayes\n",
        "* Support Vector Machine\n",
        "\n",
        "We are given a train set, and a separate test set. So, we test out model against the given test set. We also divide the training set into 2 sets: train set and cross validation set so that we can tune the hyperparameters and choose the one which gives the maximum accuracy for the cross validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUFJSJhnfoU2"
      },
      "source": [
        "#import all the libraries\n",
        "from typing import *\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import re\n",
        "from copy import deepcopy\n",
        "from joblib import dump, load"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtvjylFyvmmC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bdd4bcb-3bd3-4619-cbae-24b8f2294273"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqq5BBUne2as"
      },
      "source": [
        "# Exploring the dataset\n",
        "We now load the dataset and do some preliminary exploration of the data. This helps us better understand the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "618mjhaUewD3",
        "outputId": "337d1f04-5e38-4f8a-a9c7-5ed37fee692d"
      },
      "source": [
        "#Download the dataset\n",
        "!gdown --id 10N4pLNsHD69tv5DbJ-cji6s742wVXelb\n",
        "from zipfile import ZipFile\n",
        "with ZipFile('jigsaw-toxic-comment-classification-challenge.zip', 'r') as zipObj:\n",
        "   # Extract all the contents of zip file in current directory\n",
        "   zipObj.extractall()\n",
        "with ZipFile('sample_submission.csv.zip', 'r') as zipObj:\n",
        "   # Extract all the contents of zip file in current directory\n",
        "   zipObj.extractall()\n",
        "with ZipFile('test.csv.zip', 'r') as zipObj:\n",
        "   # Extract all the contents of zip file in current directory\n",
        "   zipObj.extractall()\n",
        "  \n",
        "with ZipFile('test_labels.csv.zip', 'r') as zipObj:\n",
        "   # Extract all the contents of zip file in current directory\n",
        "   zipObj.extractall()\n",
        "\n",
        "with ZipFile('train.csv.zip', 'r') as zipObj:\n",
        "   # Extract all the contents of zip file in current directory\n",
        "   zipObj.extractall()\n",
        "!rm sample_submission.csv.zip test.csv.zip test_labels.csv.zip train.csv.zip jigsaw-toxic-comment-classification-challenge.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=10N4pLNsHD69tv5DbJ-cji6s742wVXelb\n",
            "To: /content/jigsaw-toxic-comment-classification-challenge.zip\n",
            "55.2MB [00:00, 133MB/s] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AO-FOTzYcI51"
      },
      "source": [
        "#load into dataframe\n",
        "sample_sub_df = pd.read_csv('sample_submission.csv', delimiter=',')\n",
        "test_df = pd.read_csv('test.csv', delimiter=',')\n",
        "test_label_df = pd.read_csv('test_labels.csv', delimiter=',')\n",
        "train_df = pd.read_csv('train.csv', delimiter=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "5wRk6Q3MgP99",
        "outputId": "b7cb0130-3738-4d11-9d39-32e4ca06dcc4"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... identity_hate\n",
              "0  0000997932d777bf  ...             0\n",
              "1  000103f0d9cfb60f  ...             0\n",
              "2  000113f07ec002fd  ...             0\n",
              "3  0001b41b1c6bb37e  ...             0\n",
              "4  0001d958c54c6e35  ...             0\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUyS4Y-rggpN"
      },
      "source": [
        "There are 6 categories of toxicity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNWzy0VFgbOv",
        "outputId": "3e533afa-64aa-4f4d-d99c-dc12e7c5ecf9"
      },
      "source": [
        "train_df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 159571 entries, 0 to 159570\n",
            "Data columns (total 8 columns):\n",
            " #   Column         Non-Null Count   Dtype \n",
            "---  ------         --------------   ----- \n",
            " 0   id             159571 non-null  object\n",
            " 1   comment_text   159571 non-null  object\n",
            " 2   toxic          159571 non-null  int64 \n",
            " 3   severe_toxic   159571 non-null  int64 \n",
            " 4   obscene        159571 non-null  int64 \n",
            " 5   threat         159571 non-null  int64 \n",
            " 6   insult         159571 non-null  int64 \n",
            " 7   identity_hate  159571 non-null  int64 \n",
            "dtypes: int64(6), object(2)\n",
            "memory usage: 9.7+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bV1GJVI7g4rd"
      },
      "source": [
        "There are 159571 rows and no null values\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1TloNh6g3Xc",
        "outputId": "d7379c98-1a53-4055-a75b-1bf41a97a177"
      },
      "source": [
        "#checking if there is any imbalance in the dataset\n",
        "cols = [\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]\n",
        "print(\"unique values\")\n",
        "for col in cols:\n",
        "  print(col)\n",
        "  print(train_df[col].value_counts())\n",
        "  print(\"*\"*29)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unique values\n",
            "toxic\n",
            "0    144277\n",
            "1     15294\n",
            "Name: toxic, dtype: int64\n",
            "*****************************\n",
            "severe_toxic\n",
            "0    157976\n",
            "1      1595\n",
            "Name: severe_toxic, dtype: int64\n",
            "*****************************\n",
            "obscene\n",
            "0    151122\n",
            "1      8449\n",
            "Name: obscene, dtype: int64\n",
            "*****************************\n",
            "threat\n",
            "0    159093\n",
            "1       478\n",
            "Name: threat, dtype: int64\n",
            "*****************************\n",
            "insult\n",
            "0    151694\n",
            "1      7877\n",
            "Name: insult, dtype: int64\n",
            "*****************************\n",
            "identity_hate\n",
            "0    158166\n",
            "1      1405\n",
            "Name: identity_hate, dtype: int64\n",
            "*****************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKqocgEHhGls"
      },
      "source": [
        "* For each category, there are two classes: 0 (the comment is not toxic), 1 (the comment is toxic and the toxicity falls in this category)\n",
        "* The dataset is unbalanced, ie, most of the comments falls have label 0 ,meaning not toxic. This makes sense, as most of the comments in the social media is positive except in certain cases (in case of conflicts, ...)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jz1-AwXhhFhG",
        "outputId": "7d15e624-4757-4766-89ce-e05bb223a76f"
      },
      "source": [
        "#check if \"id\" has any info about the comment, or is just a row number\n",
        "rows = [i for i in range(train_df.shape[0])]\n",
        "sum(train_df[\"id\"]==rows)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnSapn1biSdM"
      },
      "source": [
        "So, the \"id\" column is just the row number and won't help in training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGdCo7YdiYD8",
        "outputId": "6ba0c428-bd23-47d1-fac1-b603bdf5b5d5"
      },
      "source": [
        "#remove stop words\n",
        "word_count = {}\n",
        "for sentence in train_df[\"comment_text\"]:\n",
        "  unique = set(sentence.split())\n",
        "  for word in unique:\n",
        "    if word not in word_count:\n",
        "      word_count[word] = 1\n",
        "    else:\n",
        "      word_count[word] += 1\n",
        "print(len(word_count))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "532299\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oqvi6AcjDGr"
      },
      "source": [
        "Without any preprocessing, there are 532299 unique words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXrQifHujCBN",
        "outputId": "3d632595-c6b3-4f83-80dd-5cd36d11a795"
      },
      "source": [
        "unique_char = set()\n",
        "links = []\n",
        "for row in train_df[\"comment_text\"]:\n",
        "  unique_char.update(set(row))\n",
        "  m = re.search(r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)',row)\n",
        "  if m:\n",
        "    links.append(m)\n",
        "print(len(unique_char))\n",
        "print(unique_char)\n",
        "alphabets = set()\n",
        "for c in unique_char:\n",
        "  if c.isalpha():\n",
        "    alphabets.add(c.lower())\n",
        "print(len(alphabets))\n",
        "print(alphabets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2335\n",
            "{'è¿™', 'ç‹¬', 'ã¬', 'Ñƒ', 'É‘', 'å®•', 'Ë¤', 'ãƒ', 'áº“', 'çœŸ', 'Î™', 'Â£', 'Ò¯', 'âœ', 'ç†±', 'áº¥', 's', 'Ü˜', 'æ©˜', 'à®°', 'â•—', 'Ã–', 'æ±º', 'â…', 'â•', 'áº±', 'Ìº', 'â—„', 'ï½', 'Ïˆ', 'à®’', 'âˆ™', 'ä½ ', 'Â±', 'â‰¤', 'Ñš', 'Óœ', 'æ‰€', 'Ä¾', 'å¹²', 'æ„›', 'Î¾', '@', 'ÄŠ', 'Éª', 'å•¥', 'ã‚®', 'à§³', 'ã¨', 'ç¥–', 'å¤ª', 'ä¹', 'd', 'â€²', 'á¹­', 'å²¡', 'Ì‰', 'ĞŒ', 'ğ’³', 'ãƒ­', 'Ê¼', 'é«˜', 'â€', 'è¨€', 'w', 'èª', 'y', 'á»‘', 'Ø¸', 'à¥†', 'Ğ£', 'ãŠŸ', 'Ä®', 'á¹', 'Ü', 'ë ¤', 'ä¹™', 'Ğ­', 'à§¨', 'å­«', 'å¸«', 'ã§', 'Ê€', 'à¦­', 'Çš', 'Ê‹', 'â˜¼', 'à¤˜', 'è®º', 'âˆ†', 'æ‹¬', 'áƒ', 'á½‚', 'İ­', 'é‡Œ', 'ç‹', 'Å°', 'Ã…', 'àº‡', 'äºº', 'Ø©', 'ã¥', 'ã‚Š', 'Êƒ', 'æ•', 'à¤£', 'é¹¿', 'Â¥', 'Ã§', 'â•š', 'éƒ¡', 'ãƒ³', 'é¡¹', 'åŸ', 'ãƒ–', 'á¹†', 'ã ', 'á¿¶', 'æ°‘', 'Ç‚', 'N', 'É', 'é–¢', 'à¥©', 'æ³¢', 'Ê·', 'z', 'ã', 'Ë¢', 'â•«', 'éš¨', 'X', 'ä¸ª', 'L', 'Ëœ', 'Î¼', 'è°·', 'é¾™', '\\x94', 'ÅŒ', 'å›', 'æ¼¢', 'Å¦', 'Øº', 'Ç”', 'ä½', 'ğŸ˜‰', 'â—”', 'à¥‰', 'l', 'Ò…', 'ã¹', 'È²', 'ğŒ°', 'â€˜', 'èƒœ', '×', 'ã‚¤', 'à®‡', 'à®Ÿ', 'è°¢', 'ã¸', 'à¥', 'ÑŒ', 'â˜¢', 'âˆ«', 'Å', 'ãŠ', 'â…œ', 'Ù¾', 'á¸¸', 'Ê', 'â‹…', 'ã‚·', 'Ã·', 'Î©', 'ã†', 'ğŸ™‰', 'è¥¿', 'ãš', 'æˆ‘', 'æ›¸', 'ìŠ¹', 'ãƒœ', '× ', 'Õˆ', '\\u202b', 'å µ', 'h', 'å¤', 'K', 'àº²', 'ã„¤', 'ë…', 'àº¹', 'Ã±', 'â…“', 'Å²', 'U', 'à¸¸', 'à¤…', 'Å„', 'Î’', 'è¦', 'æ²»', 'à®', 'æŸ±', 'å—', 'Ğ¦', '\\x95', 'à¶­', 'è¡›', 'ç”º', 'É•', 'ãƒƒ', 'Å½', 'à±', 'Ã˜', 'â‰½', '\\uf737', 'è–¬', 'ã‚´', 'ï¾‰', 'Ä±', 'ç‰ˆ', 'à¥‹', 'ã‚¯', 'é»„', 'ÉŸ', 'Ã¡', 'Â»', 'á»¸', 'è¨', 'é ­', 'â˜„', 'Ä¼', 'à§Œ', 'Ì¯', 'â™€', 'åˆ', 'Ã¼', 'ã‚', 'éƒ¨', 'â²§', 'Ì‚', 'ç•Œ', 'ãƒ‘', 'Ç', 'á¹£', 'ëˆˆ', 'é©š', 'à¯ˆ', 'ç‰©', 'â', 'à²¨', 'à¦Ÿ', 'âœŒ', 'è¿‡', 'Ã†', 'Ï', 'çš„', 'ì„œ', 'â…', 'â¿', 'Å³', 'Ç', 'à¸²', 'à»„', 'èŠ¦', 'É¾', 'à¤¿', 'ğŸ‘', 'É“', 'Â¢', 'â˜®', 'â€¢', 'à¶»', 'â˜›', 'Éœ', 'ê³µ', 'Ê”', 'çŒ«', 'à¤', 'âŸ²', 'å…¬', 'à®©', 'Ã—', '×¨', 'á¸ ', 'Ë‘', 'é ', 'É', 'Ğ¨', 'â‚­', 'à´®', 'Ù‘', 'â””', 'ã‹', ']', 'Â´', 'å‹', 'Î®', 'é§…', 'è¬š', 'â†„', 'Ğ¢', 'á¸·', 'ä½†', 'æ‘', '\\u2002', 'Ã¹', 'ãƒ¡', 'ç¾', 'è»', 'â˜…', 'â”‚', 'ç¨¿', '\\u2009', 'Âº', 'Å±', 'é’¾', 'à¸•', 'ê°•', 'ì¹¨', 'Ã°', 'â€’', 'â„–', '5', 'Å«', ')', '×•', 'ã£', '0', 'ã‚ª', 'Å', 'áº½', 'çµ¡', 'Ñ—', 'É¿', 'ã‚’', 'å ', 'é›', '\\uf734', 'à¤·', 'èªª', 'Î ', 'ãƒ£', 'àº', 'ç”²', 'á´¬', 'Ì©', '×“', 'Â³', 'è¨˜', 'Ä ', 'áƒœ', 'â‚³', 'Ä«', 'â¨', 'â€½', 'à®¤', 'ì°œ', 'è¬', 'ë²ˆ', 'à§', 'Ğ', 'å—', 'ï½¨', 'Â¤', 'Ãœ', 'Ğ¿', 'ê¸°', 'ä¹ˆ', 'Ì', 'âª', 'ãƒ¥', 'è¨³', 'İ£', 'Î‘', 'æ‰¿', 'Ç˜', '7', 'å®¶', 'ä»–', 'ã‚°', '×˜', 'æ´²', 'à¤¹', 'ï¼š', 'å¢“', 'ç‰', 'âœ«', 'ç´”', 'Ø¹', 'Í§', 'å·', 'å‚³', 'á»‰', 'ï¼', 'á½°', 'âˆ‡', 'åŠ´', '-', 'ã‚‹', 'å', 'å†', '_', 'å…§', 'é—˜', 'Å“', 'àºµ', 'åŠ‡', 'Õ´', 'å»', 'åŒ—', 'å¹´', 'à²¾', 'é™¢', 'æ“', 'æ”¿', 'â…”', 'Ù…', 'Ğœ', 'è¿·', 'Í‡', 'æ‰‹', 'æ»¡', 'á¼ ', 'Ø³', 'ã‚‚', 'Ê¾', 'Êœ', 'Ê°', 'é®®', 'â‚£', 'â€', 'â‚¤', 'âœ¤', 'ğŸ˜', 'ã‚ƒ', 'ï¼˜', 'æ‹‰', 'Ğ³', '×¡', 'à¸£', 'è¡Œ', 'ğŸ’œ', 'à»œ', 'æƒ…', 'æ ¡', 'å·²', 'á¸¥', 'È‹', 'ã„', 'á½€', 'æ', 'Ğ¡', 'â”œ', 'Ä­', 'Ö¶', 'ã¡', 'å±±', 'Â½', 'Ğª', 'æœ€', 'É”', 'ì¹ ', 'R', 'Â®', 'Ø®', 'Ö‘', 'å‰', 'ì²­', 'Å˜', 'è‡¼', 'ğŸ’¬', 'ã©', 'ã', 'Â²', 'Å»', 'å†’', 'å§»', 'İŸ', 'á½¶', '×™', 'Ù‚', 'ãƒš', 'Î£', 'á›Ÿ', 'à®¾', 'àµ†', 'Ğ•', 'âˆ‘', 'ä¸–', 'Ë¡', 'æ’', 'â”', 'ëŒ€', 'æ¡œ', 'Ã¿', 'åˆ', 'â‚®', 'å•¼', 'á¹—', 'â–³', 'Ğš', 'é€™', 'å–·', 'É›', 'Ğµ', 'ç¼', 'åœ¨', 'æµ·', 'É£', 'Î¥', 'à¥ˆ', '\\u202c', 'æ˜¯', 'Ò‰', 'Ã“', 'Ø¢', 'Ïƒ', 'ğŸ˜‚', 'Ö°', 'áƒ—', 'Ä½', 'Ê¡', 'Ñ‘', 'b', 'â•Ÿ', 'â¤', 'é†«', 'å€’', 'è‘¦', 'Î¨', 'æ•…', 'ãƒ¼', 'Ä´', '\\uf03d', 'ğŸ¤', 'Ã‹', 'Ä¿', 'à®¯', 'Û¸', 'â™”', 'ã¯', 'å…±', 'àº´', 'æ¢', 'Ğ›', '×§', 'ç·¨', 'Ã™', 'æ´»', 'â€º', 'ã¿', 'Ù', 'è˜­', 'äº¬', 'å¾¡', 'Ã­', 'ç†Š', 'â™©', 'àº¡', 'Ñ‰', 'ã°', '\\u200e', 'Ä¶', 'ì•¼', 'æ»¬', 'Ğ²', 'â½', '×›', 'áŸ‚', 'Î', 'ç«™', 'âœ‹', 'ç™½', 'í˜¸', 'á¹ƒ', 'çµ±', 'ï½ƒ', 'æ”¹', 'â±£', 'å¾Œ', 'å‡º', 'ã‚»', 'Ê™', 'Ù„', 'Â¿', 'Ò‘', 'Å', 'â—¥', 'æµ', 'æŠ•', 'âœ—', 'İœ', 'âœˆ', 'è¢', 'å’¨', 'è¦–', 'ÙŠ', 'à¦‚', 'â‰¼', 'è€Œ', '\\uf738', 'á»‡', 'å', 'Øª', 'æ…•', 'çµ‚', 'å±‹', 'èŒƒ', 'â‚§', 'à¥§', 'ã‚¶', 'ç›Š', 'Îº', 'â„', 'â¦', 'ğŒ²', 'â„“', 'â˜‘', 'ë‹¤', 'Ã¢', 'ãƒ—', 'à¯¹', 'Ãš', 'ĞŸ', 'É¬', 'ç‰¹', 'â•¦', 'ç½‘', 'Ï·', 'Î¹', 'æ–¹', '\\uf739', 'á§¾', 'àº¸', 'á¸', 'ãµ', 'Ã£', 'ã˜', 'æœ', 'Úˆ', 'Ü£', 'Ñ†', 'ã“', 'è¬›', 'âœ­', 'ä¿‚', 'ë¹ ', 'áƒ”', 'ì´', 'æ—©', 'Ã²', 'ê°œ', 'á¼”', 'â¥', 'Ëˆ', 'Å‡', 'È³', 'Õ·', 'ã€‹', 'ï½±', 'å•†', 'Ï', 'ä¸»', 'Ã', 'Ãƒ', 'ë§ˆ', 'àº™', 'ï½‹', 'â™', 'á¿ƒ', 'ï¼', 'â‡', 'é³´', 'á¼¡', 'á¾½', 'ç”¨', 'æŸœ', 'à¤¥', 'â„¥', 'ë§›', 'É«', 'å‰¯', 'Â©', 'à¸¢', 'è© ', 'ï¼', 'Ğ°', 'àª¾', 'èˆª', 'âœ', 'å°ˆ', 'Ä·', 'è›‹', 'ß·', 'ãƒª', 'è‡§', 'à¯‡', 'ï¼‘', 'É™', 'à¸¥', 'æ—', 'Ä›', 'à»', 'ã', 'ã²', 'áƒ¦', 'ãƒ»', 'ç”Ÿ', 'ã‘', 'à¨°', 'Ğ ', 'â˜¸', 'Ê›', 'à²¦', 'â”', '×’', 'â„±', 'à¤–', 'è¡¨', 'ä¸œ', 'à¤”', 'æ¸ˆ', 'ÑŠ', 'àª¦', 'ç¹”', 'âŠ', 'ç²µ', 'å·', 'Í', '\\u2060', 'ä¾†', 'ã€Š', 'Ê', 'æ–‡', 'éŒ²', 'ç‚º', 'áº«', 'Úœ', 'éƒ½', 'çƒ', 'è¢«', 'áš¹', 'ã”', 'ã„§', 'Í–', 'âœ„', 'á½º', 'â‚°', 'á½„', 'å¥', 'áš', 'çŸ³', 'æ„', 'å¤–', 'à¤¡', 'Ï‚', 'á¹¢', 'Îµ', 'ã', 'é£', 'Ğ¶', 'â™£', 'Ñ', 'ãƒ ', 'Ø«', '×–', 'Â°', '!', 'ä»€', 'âœ¿', 'Ä', 'â‰ ', 'ç·£', 'â”', 'à°…', 'Æ¬', 'ì§', 'æ–­', 'á´·', 'æ¸…', 'Î¿', 'Ú†', 'ãƒ¯', 'çµ„', 'ã‚½', 'Ïº', 'Â¦', 'Ğˆ', 'ç¬‘', 'æ’°', 'Ã«', 'å·±', 'çŒ›', 'à¹ˆ', 'İ“', 'Åœ', 'Ğ‚', 'Îˆ', 'ì˜', 'ğŸŒ', 'â„ ', 'ãƒ•', 'á»©', '/', 'èª¿', 'å™¨', 'Ğ¸', 'Ï‡', 'Ä¦', 'Äª', 'à¥ª', 'ã‚ˆ', 'à¨¨', 'Ë€', 'á¹›', 'æ†²', 'Ï…', '\\uf735', '|', 'ã‚³', '\\xa0', 'â˜¿', 'á¹¯', 'à´µ', 'Ø¬', 'Íš', 'c', 'ç‘š', 'Î•', 'æº–', 'D', 'ì§‘', 'å‹•', 'éŠ€', '\\x9d', 'æ´›', 'ç¨', 'Ù', 'Ñ’', 'Ø²', 'å¥½', 'Î¯', 'ãƒ§', 'áº£', 'åŒ…', 'æ³•', 'È™', '3', 'É­', 'ã»', 'Ï‰', 'å®¹', '\"', 'â°', 'Å¬', 'Ğ‰', 'Ä‹', 'Ã•', 'ğŸ„', 'Å—', 'Å•', 'âˆ§', 'Ã„', 'ä¸ˆ', 'ê³ ', 'É°', 'åŸº', 'â€³', 'å®š', 't', 'á¼˜', '`', 'Ù‹', 'Ä', '\\u202a', 'è‹¥', 'ç¶™', 'ç•ª', 'à¦…', 'à¸¿', 'âˆ…', 'ç›’', 'É²', 'Ã¬', 'Ä…', 'Ø­', 'é¢¨', 'Å¯', 'Ğ–', 'ç„‰', 'ãƒ˜', 'äº†', 'âœ', 'áµƒ', 'áº¹', 'Ä¢', 'Ã¨', 'àº±', 'ç ‚', 'à®¿', 'å­—', 'Ñ•', 'Ä£', 'ÊŒ', 'ÃŒ', 'Ğ…', 'í˜ˆ', 'Çœ', 'è³œ', '8', 'Äˆ', 'Å‚', 'É»', 'â™‚', 'Ã¯', '\\u2004', 'å°±', 'è¯‘', 'à¥¬', 'â˜¾', 'æ¼”', 'à·”', 'Î½', 'é€ ', 'ã—', 'á€', 'É’', 'à¥ƒ', 'å¿—', 'Ã ', 'Ê', 'Ç£', 'Ã´', 'Î›', 'Ğ¥', 'Éš', '\\uf6fc', 'é™ˆ', 'á»£', 'æ ¼', 'â˜¤', 'ï½', 'æ–¼', 'é»ƒ', 'â€¹', 'Å’', '\\uf731', 'é…¸', 'Í®', 'ç­†', 'æŠ—', 'ï½·', 'â”˜', 'èŠœ', 'Ë', 'Å', '×”', 'ã™', 'â€ ', 'â²Ÿ', 'çŠ', 'ãŒ', 'áµ®', 'é›ª', 'Ø±', 'áº¯', 'à§¦', 'Õƒ', 'â”“', 'ã‚…', 'êµ¬', 'æœŸ', 'q', 'Ç½', 'â–ˆ', '=', 'å³', 'è¨£', 'â– ', 'æŒ‡', 'å±Œ', 'Î“', 'Ï', 'ã³', 'Å', 'Ïœ', 'é«”', 'à°µ', 'à¤¤', 'Ğ§', 'âœ½', '<', 'Ñ‡', 'É¡', 'Ç‘', 'å·¾', 'Ø°', 'Ç¢', 'â‚¥', 'ãƒ’', 'Í©', 'â‚¬', '~', 'âˆ‚', 'Ã½', 'å§“', '\\u200b', 'ë„˜', 'Å†', 'Åˆ', 'ë¹„', 'ç«', 'èª', 'Ä“', 'å’Œ', 'à¦¸', 'è‚¥', 'ĞŠ', 'é€£', 'ç‰›', 'ã‚', 'Ì¿', 'à¸', 'á½²', 'â‰¥', 'â†’', 'ã¤', 'à¥', 'Ñ˜', 'áƒ¡', 'Ç“', 'è‡­', '>', 'Å¼', 'Ñ„', 'àª…', 'à©', 'Ã¤', 'ğŸ˜„', 'ÑŸ', 'ğŸ¼', '6', 'ã‚­', 'ì†Œ', 'Í°', 'æ¿¤', 'å¤©', 'à¦¤', 'ç£', 'â™ª', 'å„€', 'ä¼', 'âˆ€', 'è¿', 'Âª', 'àªµ', 'O', 'Ç', 'ãƒ›', 'V', 'á»‹', 'Ê•', 'ã€', 'á¹…', 'Y', 'â…›', 'äºŒ', 'æ¿Ÿ', 'ìˆ', 'à¤ª', '\\uf0b7', 'Ã”', 'ãˆ', 'åƒ‘', 'ä»£', 'ä¹', 'â€¿', 'á»™', 'è—©', '×—', 'à¦²', '×‘', 'å¡', 'Ì„', 'à¨¼', 'Ä˜', 'ãƒ®', 'â˜', 'Õ©', 'Å›', '×', 'âŠ‚', 'ç«œ', 'áƒ®', 'Î¡', 'à®œ', 'è·¯', 'í‹€', 'Ä‡', 'à¦¦', 'å°', 'Ø¡', 'à¯Š', 'é•¿', 'Ë ', 'â”—', 'â˜¯', 'ï½', 'ç¦', 'â˜ ', 'â¨¹', 'âˆ—', 'è¼', 'ç£', 'à¦°', 'Å¿', 'á¿†', 'Ä¬', 'à¤¶', 'Ç', 'â†¨', 'âœ˜', 'ÇŒ', 'Ğ', 'Õ«', 'è¯', 'æµ¦', 'à¨®', 'Å¸', 'à¦‡', 'Ãˆ', 'Îœ', 'ï¼´', 'ä¸‹', 'â–¾', 'ç‰', 'â„', 'à®£', 'æœ‰', 'Ù‡', 'o', '\\u2028', 'ãª', 'Å£', 'à¤¨', 'á½…', 'Ã', '\\x97', 'Ğ®', 'Õ¸', 'â‚©', '\\u2003', 'å¼ ', 'ç¿', 'æ™®', 'Ñ§', 'É ', 'å‹™', 'âŸ¨', 'Ä—', 'å®¢', 'Â¡', 'ã‚¹', 'å†…', 'àº•', 'á¸Œ', 'Ì—', 'â„š', 'Ê‚', 'æ²–', 'ãƒ', 'ç™¾', 'Û©', 'á¼€', 'Ûµ', 'ãƒŠ', 'Å´', 'à©­', 'ç«¹', 'á›‡', 'ë¯¼', 'ÄŒ', 'Ãª', 'W', 'á»«', 'è‰', 'å› ', 'å®˜', 'à´‚', 'â™š', 'â‚¡', 'à¦•', 'ãƒ½', 'ë‚ ', 'â‚¯', 'Â§', 'ç¶­', 'Ã‰', 'Î¦', 'à²…', 'ì¡', '×¦', 'r', 'ä»™', 'Ä¡', 'à«', 'à¯', 'á¸¶', 'p', 'Ö¼', 'ÊŸ', 'Å·', 'åœ°', 'è¼¯', 'å ´', 'Ã›', 'Ä¨', 'åœŸ', 'ÎŸ', 'à¤¦', 'å‹', 'ä»¤', 'E', 'Ä', 'È›', 'Ğ', 'å¥³', 'çˆ½', 'ç¾', 'åº¦', 'É®', 'ã¾', 'C', 'J', 'ç«‹', 'å²', 'à®²', 'Ã', 'æƒ‘', 'ÅŸ', 'ä¸‡', 'à®†', 'â²±', 'æ¢¨', 'ìˆœ', 'äº', 'ã‚‰', 'è¯', 'Ğ©', 'à¤«', 'àº—', 'á»¥', 'á¹š', 'Ğ¯', 'ÎŠ', '\\u200f', 'Ç«', 'ã€', 'â†‘', 'Î¬', 'é”', 'â“', 'Ø¨', 'Ê', 'ì', 'Ö‚', 'æœª', 'å', 'à¤†', 'áŸ’', 'Ä”', 'å¯', 'êµ°', 'ï¸µ', 'å°‘', '#', 'å¸', 'åˆ—', 'æ™¯', 'à­¯', '\\x93', 'ã‚‡', 'Åª', 'è®°', 'éº—', 'ã‚±', 'Ğ¹', 'æˆ–', 'è¶', 'â€œ', 'à¥«', 'É', 'g', 'è–©', 'Ó¢', 'á‹­', 'Ä™', 'Ğ™', 'Â¸', 'Ê§', 'à¯†', 'Â¾', 'âœ‰', 'éœ€', 'ØŒ', 'çª£', 'á¸Ÿ', 'æ™‚', 'Ê¿', 'à¶š', 'å¯¾', 'äº•', 'é¡Œ', 'à®‰', 'â™¨', 'â˜', 'É¯', 'Î—', 'é¢', 'à¦œ', 'Ì¹', 'àº›', 'ä¸­', 'â”Œ', 'á¶', '\\x7f', 'Ùˆ', 'à¥¯', 'á¸¤', 'â', 'ç›®', 'É˜', 'ËŒ', 'H', 'â‚«', 'à¤®', 'ã¦', 'ì²«', 'å¯¹', ' ', 'â†“', 'Åµ', 'æ±‚', 'É©', 'e', 'â—…', 'â—‹', '×¢', 'ğŸ˜¢', 'í—Œ', 'ï½—', 'à¤ ', 'áƒ¤', 'å¦ˆ', 'â‚', 'â€”', 'àºª', 'â•©', 'å­', 'æ¯', 'Î±', 'é˜¿', 'à¹', 'à¤¯', 'â„¢', 'ä¸', 'â†', 'àº„', '×¥', 'ãƒ¬', 'ê¸¸', 'èµ·', 'Å‘', 'ãƒ‹', 'Ø·', 'á›', '\\uf04a', 'ï½', 'Ñˆ', 'è´', 'ÊŠ', 'ã€', '\\x91', 'ãƒ“', 'Å¡', 'á¿–', 'â²©', \"'\", 'à¦¨', 'è€…', 'ï½¡', 'è‹±', 'é™', 'à®š', 'Ø£', 'á¼', 'Ìˆ', 'Ìª', 'Ãµ', 'Ä°', 'Ñ€', '\\u200a', 'ç™»', 'æ€', 'Ì¥', 'Ì®', 'è¡€', 'æ™º', 'æ²³', 'ï¾', 'à¤‚', 'à®µ', '×©', 'Õ‡', 'ç¥', 'à¼†', 'Ñ', 'Å”', 'â€¦', 'Ø¦', 'â‚µ', 'ì£¼', 'á‰µ', 'Û', 'åˆ¶', 'Å¨', 'æœ¬', 'ä½“', 'á»¯', 'â—¦', 'à¸­', 'ï¼Ÿ', 'Ğ', 'å¥', 'áº¿', 'é¾œ', 'å…«', 'â—¯', 'F', 'Çƒ', 'â€–', 'ï¾ƒ', 'â˜º', '\\n', 'çœŒ', 'å¿ƒ', 'ã‚„', 'â™ ', 'å£¹', 'å¸‚', 'áƒ•', 'a', 'Ã©', '^', 'Êˆ', 'Ù†', 'Å', 'â˜“', 'å¾ˆ', 'åœ‹', 'ìœ ', 'Â·', 'Î‰', 'Ã', 'å—', 'æ¾„', 'Å…', 'Â¯', 'Ã¥', 'Ğ', 'á»…', 'à¶³', 'é€€', '\\uf701', 'Ê', 'ç´«', 'Å¾', 'ğŸ', 'å‘½', 'Äµ', 'à¤œ', '\\u200d', 'Î', 'Ã¸', 'Ğƒ', 'İ—', 'ã€', ';', 'à¿“', 'æ“²', 'Ê„', 'à§', 'Å€', 'ëŠ”', 'á”', 'ì²™', 'æ°¸', 'ä¿¡', 'æœ', 'Ç', 'Ó©', 'â¾', 'æ—¢', 'ã‚¸', 'áº­', 'â‚´', 'ç·š', '1', 'Ö·', 'ğŸ˜€', 'à´¾', 'Ä»', 'â„³', 'æ´', 'è£½', '*', 'ã–', 'ç¿¼', 'ä»Š', 'É¹', 'Î”', 'Ğ¾', 'åŠ ', '%', 'é€š', 'Ëº', 'ë‰´', 'â‚¢', '×´', 'Ä', 'ï¾Ÿ', 'Ê»', 'Ã¾', 'å¯¦', 'á¸¹', 'ç¸„', 'àº”', 'Ï„', 'Å¢', 'Ä•', 'â‚¨', 'çŸ¥', 'á¹«', 'æ€»', 'Äš', 'ä¾¿', 'é™º', '\\uf6de', 'ğŸ˜œ', 'v', 'è’™', 'Æ°', 'Ç°', 'Çª', 'âŠ¥', 'É±', 'ÏŒ', 'â–ª', 'á½§', 'â´', 'â˜¥', 'É¦', 'É¥', 'ã€ˆ', 'å³¶', 'à¤­', 'åœ', 'ã‚µ', 'à¦®', 'â™¦', 'Õ¿', 'B', 'à¦¯', 'à®™', 'Ñ–', 'ã‚', 'à¤²', 'é¯', 'ì¡°', 'âŸ©', 'ç”°', 'âˆª', 'à¤¸', 'à²µ', 'Öµ', 'áŸ›', 'Ä–', 'å®‰', 'è—', 'ì„ ', 'å»£', 'ç¸£', 'Ñ…', 'à¸›', 'É¤', 'ä¸¦', 'ç§‘', 'ãƒ«', 'å', 'à³', 'Ç', 'é–©', 'ìš”', 'è¡“', 'ç»', 'à·Š', 'ğŒ´', 'Î†', 'æ–°', 'Ùƒ', 'âœ°', 'Ì“', 'ê²½', 'á¸»', 'k', 'çœ', 'ğŒ¿', 'é›»', 'ç¾Š', 'è¼¸', 'Ñ›', 'Ã', 'æ­¡', 'æ —', 'ä»˜', 'å¤‰', 'é‡‘', 'Ë‰', '\\x92', 'é˜²', 'âœ“', 'æœ±', '\\u202f', 'Ã³', '2', 'Ã®', 'é›²', 'ãƒ´', 'áº·', 'x', 'Ä¤', 'â˜‡', 'åª', 'Ğ†', 'éŸ¦', 'ãƒ”', 'åˆ©', 'â†•', 'Ú¯', 'â—•', 'à®•', 'Ç–', 'Õ¶', 'æ´ª', 'å£°', 'Ö€', 'ë¦¬', 'å“', 'ã‚¨', 'â‡„', 'ç£¨', 'â—', 'æ‚¨', 'à°¾', 'åºœ', 'Ïš', 'ã‚¡', 'Í¨', 'â€•', 'Ê‰', 'ã„‰', 'ğŸ—½', 'Ø¤', 'â™¥', 'åŠ©', 'à´Ÿ', 'å›½', 'Q', 'á¹‚', 'â•¢', 'âˆ´', 'Òš', '9', 'æ­¦', 'çŠ¬', 'i', 'Î', 'åƒ', 'åš', 'Î–', 'ÛŒ', 'â˜', 'Ú°', 'à¤¼', 'â', 'Å­', 'à¤¬', ',', 'ãƒŒ', 'ãƒ©', 'áº§', 'Ğº', 'æ³›', 'ã‚«', 'å…¼', 'ë£¡', '?', 'Åº', 'ç–‹', 'ë°›', '×€', 'à¦¬', 'æ±', 'Î', 'Ğ´', 'Ì°', 'â„', 'à¸§', 'á½¸', 'á»ƒ', 'ã‚¿', 'ç´…', 'è‡º', 'Ê¨', 'é’', 'Ò', 'Ñ‚', 'âŠ—', 'Ğ‡', 'é›–', 'ğŸ™ˆ', 'æ¸¡', 'é™³', 'æ¡”', 'é•·', 'â”ƒ', 'Å©', 'Ï¾', 'â€¡', 'ç¨±', 'â€‘', 'æ°´', 'Â¼', 'è–', 'æ¹–', 'ç–†', 'Ğ’', 'ã‚“', 'Â¶', 'àº»', 'ï¿½', 'à¤—', 'ãƒˆ', 'Ğ»', 'æ±Ÿ', 'à·€', 'Ğ«', 'ãŸ', 'å', 'âˆ’', 'áƒ', 'áƒš', 'ã­', 'Ãº', 'é¾±', 'ç¿»', 'Ä¹', 'åŒº', 'Å¶', 'æ¶›', 'ã‚', 'ã……', 'åŸ·', 'ï¼–', 'à¦¹', 'Ü', 'ë¬¸', 'ä¸€', 'ì¸', 'í¸', 'âœ', 'á¹œ', '{', 'ç‰¡', 'àº¥', 'æ¬¡', 'ç´ ', 'å…µ', 'ã‚¢', 'àµ‹', 'Ã', 'Ê¢', 'à¯‹', 'à² ', 'æ…§', 'à¥­', 'ã•', 'Ğ”', 'æ„Ÿ', 'à¸„', 'Ò', 'â‰¡', 'à¨–', 'Ğ±', 'è¯', 'Ì²', 'ç­', 'Å¹', 'Ì«', 'Ìƒ', 'Î¶', 'æ¥Š', 'Ã¶', 'à»ˆ', 'á¹¬', 'ã€', 'Ì', 'ì•„', 'è¶Š', 'ã‚£', 'ãƒ', 'âœ’', 'ä¾‹', 'ì•ˆ', 'áƒ·', 'Ğ¬', 'â˜œ', 'âœ”', 'Ê²', 'â˜£', '×š', '\\uf730', 'ã€Œ', 'ì—­', 'å…ˆ', 'M', 'ÄŸ', 'ç²¿', '+', 'ğŸ™Š', 'Ã¦', 'è‰¯', 'Û¾', 'ï½Œ', 'â‰', 'Ò›', 'â€§', 'Ã‚', 'âŒ©', 'Òˆ', 'Ú©', 'Û»', 'àºˆ', 'éƒ­', 'æ±‰', 'Õ¡', 'à§‹', 'ÎŒ', 'ã®', 'à°¨', 'á¹', 'Å ', 'Â¹', 'â±·', 'è¨ª', 'ï¼', 'à¤‹', 'Ç’', 'Å¤', 'è±', 'ä¸Š', 'á¿·', 'âœ†', 'ğŸ˜ƒ', 'Ñ', 'Ø´', 'ã‚¦', 'Ñœ', 'Ñ“', 'à¨œ', 'Ğ', 'âŠ™', 'ãƒ¢', 'áµ', 'è¿‘', 'â˜»', 'á»', 'å­¦', 'ï¼ˆ', 'ğŸ’©', 'f', 'à¥', 'åˆ°', 'âˆˆ', 'äº‹', '4', 'Í‘', 'Û', 'à¤‰', 'ğŒ¹', '\\xad', 'ï¾', 'áº¼', 'â‚‚', 'Î­', 'åƒ', 'âš‡', 'ã„', 'Ö²', 'Ã‘', 'Å‹', 'áµ€', 'Ä', 'Î»', 'à¤µ', 'Ö¸', 'Í²', 'å››', 'Â¬', 'éƒ', 'Ñ”', 'à¯€', 'Ì†', 'Ä¯', 'á¾³', 'è©±', 'â˜ƒ', 'Å§', 'Ìœ', 'å¤§', 'å¯§', 'Æ’', '×Ÿ', 'Ç§', 'æ›¹', 'ÃŸ', 'â˜˜', 'Z', 'å°', 'åŠ‰', 'ã', 'ãƒ†', 'á¼´', 'Ã', 'ï¼¡', '[', 'â˜€', 'à®…', 'È—', 'æŠ˜', '$', 'ã„·', 'ãœ', '\\uf0a7', 'Ø§', 'ä»¥', 'à¸¡', 'Ñ™', 'é¦¬', 'Ø¥', 'Ï†', 'â…¡', 'ç„¶', 'Å', 'á¼°', 'Î´', 'ï¬‚', 'â–«', 'â–¶', 'u', 'Ó§', 'çƒ‚', 'É´', 'á»', 'Äº', 'àª¨', 'P', 'â€“', 'æ—¥', 'É¸', 'å³', 'âŠ•', 'à¤Ÿ', 'Í¡', 'âˆš', 'â˜½', 'á´¥', 'á»', 'Ê‘', 'Î˜', 'à´¸', 'ë„', 'Î²', '×¤', 'Ó¨', 'æ­¥', 'Ğ‹', '\\ufeff', 'é¡µ', '\\uf6d9', 'Ã’', 'è¾º', 'Ä', 'É§', 'á´€', 'ë³´', 'à®¨', 'à§‡', '×', 'é¢ˆ', 'Ä¥', 'Ø¯', 'Å–', 'áµ—', 'Â¨', 'ä»®', 'à¯', 'à¦¼', 'Üª', 'æ', 'â”›', 'ä½¿', 'Øµ', 'æ¥©', 'áƒ›', 'à®±', 'å²©', 'âœ', '(', 'á¾¶', 'Éº', 'Ğ˜', 'Ì¼', 'ä½©', 'Å®', 'à¤°', 'ãƒ‡', 'Ö´', 'æˆ', 'è²¢', 'àº', 'à¤', 'ç¾©', 'àº¼', 'èˆ¹', 'å¡©', 'Ä§', 'å€‘', 'â˜', 'Õ£', 'æºª', 'Ã€', 'áƒ', 'áƒ’', 'â“‰', 'à¤¾', 'â•', 'æ¾', 'Ì', 'áƒ˜', 'æ’ƒ', 'è«–', 'éœ', 'àµ', 'á»¹', 'Ğ½', 'Ì´', 'é¸', 'æ²¹', 'áƒ ', 'â†—', 'ï¼', 'Í¤', 'Ï', '\\\\', 'ã‚Œ', 'å¹³', 'Í‰', 'Âµ', 'â–', 'Ñ‹', '&', 'ä½', 'â‰ˆ', 'â”€', 'ã…‚', 'ãƒ', 'ï¼Œ', 'Ğ·', 'Ù”', 'à´•', 'à®´', 'É³', 'à¥¦', 'Îš', 'ç…§', 'è™', 'éš»', 'à¥¨', 'Â«', 'Ã‡', 'âš”', 'Åš', 'à´¦', 'æ³¥', 'Æ', 'à®ª', 'Ì­', 'à¨¾', 'ç€¾', 'àº°', 'Äœ', 'æ—­', 'Äƒ', 'ì§€', 'á½¼', 'ã€‚', 'â’¶', 'à¥€', 'Å¥', 'É¶', 'â–', 'Õµ', 'â˜†', 'à§§', 'É–', 'É¢', 'ä¸‰', 'å­¸', 'æ³¨', 'Ğ—', 'Æ¡', 'á‹', 'Î·', 'å‘³', 'ä¼š', 'æ°', 'â™‘', 'é‚ˆ', 'å°»', 'Î§', 'ä»‹', 'â•‘', 'ç¥', 'æ˜', 'ğŸ“§', 'â€', 'å¸ƒ', 'Å™', 'è±†', 'ï¼‰', 'àº§', 'S', 'à®³', 'Ä†', 'Î¸', 'á¹‡', '\\uf736', 'Í™', 'É—', 'â†”', 'ãƒ', '}', 'à»‚', 'â„²', 'á¿¼', 'á½ˆ', 'à®®', 'n', 'Éµ', 'Ø¶', 'æˆ¸', 'É¨', 'âŒŠ', '×', '\\uf733', 'å•', ':', 'Ä„', 'åº„', 'ç½®', 'ãƒ„', 'åŠ', 'Ğ“', 'ã›', 'à¦¾', 'å…¸', 'Ê˜', 'å‰', 'ã’', 'Ä', 'Ğ„', 'âˆ', 'ã€‰', 'àº£', 'åŒ', 'à¤§', 'Ã»', 'Ä‘', 'ë•Œ', 'â˜­', 'á¿¦', 'àºŠ', 'â€™', 'É½', '\\u06dd', 'å', 'á¼‘', 'ğŸ˜…', 'ï½³', 'á»±', 'à°¦', 'å®ˆ', 'ãƒ‰', 'Ä’', 'Û¬', 'à¨¸', 'àº«', 'àº­', '\\u3000', 'ï½¥', 'Ä€', 'Ê’', 'á¹™', 'â—€', 'à¥®', 'ç´™', 'â™¬', 'è¦‹', 'é‡', 'Ğ‘', 'T', 'Ñ', 'ä¹Ÿ', 'Ä©', 'Ù‰', 'Åƒ', 'Í“', 'å·', 'è€', 'Ä‚', 'à¥‡', 'Ê‡', 'ã«', 'å¿«', 'åˆ€', 'â—', 'æ”»', 'ä¸ƒ', 'å¨', 'Ñ', 'åƒ', 'à´°', 'â”', 'Ë', 'â‚ª', 'İ¡', 'æ²ª', 'á¹§', 'æŸ³', 'ğŸ˜Š', 'à¥‚', 'é¾', 'à¤š', 'å¤œ', 'Ğ¼', 'â‡’', 'å½±', 'à¨«', '×œ', 'Úµ', 'm', 'æ­¢', 'æœˆ', 'è‡ª', 'é€†', 'ã€‘', 'Ö»', 'ğŸ“', 'ìƒ', 'I', 'åˆ¥', 'â‚¦', 'ç©£', 'å¿', 'è·', 'â‡”', 'â–º', 'ãƒ', 'à¹›', 'ğŸ˜”', 'á´¸', 'àº®', 'Ğ¤', 'à¤•', 'â‚ ', 'áº¡', 'ãƒ™', '.', 'Î¤', 'å†™', 'j', 'Ì ', 'ã„¨', 'á¼±', 'â–²', 'Ú¬', '\\uf732', 'é¡§', 'ÃŠ', 'G', 'â™«', 'à¤‡', 'Ä‰', '×ª', 'é™¸', 'ì²œ', 'Ê', 'Î³', 'Ï€', 'á»­', 'A', 'é™½', 'â•”', 'Ç€', 'ã‚¬', 'Ê', 'ã‚§', 'à¦¿', '\\x99'}\n",
            "1542\n",
            "{'è¿™', 'ç‹¬', 'ã¬', 'Ñƒ', 'É‘', 'å®•', 'Ë¤', 'ãƒ', 'áº“', 'çœŸ', 'Ò¯', 'ç†±', 'áº¥', 's', 'Ü˜', 'æ©˜', 'à®°', 'æ±º', 'áº±', 'ï½', 'Ïˆ', 'à®’', 'ä½ ', 'Ñš', 'æ‰€', 'Ä¾', 'å¹²', 'æ„›', 'Î¾', 'Éª', 'å•¥', 'ã‚®', 'ã¨', 'ç¥–', 'å¤ª', 'ä¹', 'd', 'á¹­', 'å²¡', 'ğ’³', 'ãƒ­', 'Ê¼', 'é«˜', 'è¨€', 'w', 'èª', 'y', 'á»‘', 'Ø¸', 'á¹', 'Ü', 'ë ¤', 'ä¹™', 'å­«', 'å¸«', 'ã§', 'Ê€', 'à¦­', 'Çš', 'Ê‹', 'à¤˜', 'è®º', 'æ‹¬', 'áƒ', 'á½‚', 'İ­', 'é‡Œ', 'ç‹', 'àº‡', 'äºº', 'Ø©', 'æ•', 'ã‚Š', 'Êƒ', 'à¤£', 'é¹¿', 'Ã§', 'éƒ¡', 'ãƒ³', 'é¡¹', 'åŸ', 'ãƒ–', 'ã ', 'á¿¶', 'æ°‘', 'Ç‚', 'É', 'é–¢', 'æ³¢', 'Ê·', 'z', 'ã', 'Ë¢', 'éš¨', 'Ó£', 'ä¸ª', 'Î¼', 'è°·', 'é¾™', 'å›', 'æ¼¢', 'Øº', 'Ç”', 'ä½', 'l', 'ã¹', 'ğŒ°', 'èƒœ', '×', 'ã‚¤', 'à®‡', 'à®Ÿ', 'è°¢', 'ã¸', 'ÑŒ', 'Å', 'ãŠ', 'Ù¾', 'Ê', 'ã‚·', 'ã†', 'è¥¿', 'ãš', 'æˆ‘', 'æ›¸', 'ìŠ¹', 'ãƒœ', '× ', 'å µ', 'h', 'å¤', 'àº²', 'ã„¤', 'ë…', 'Ã±', 'à¤…', 'Å„', 'è¦', 'æ²»', 'à®', 'æŸ±', 'å—', 'à¶­', 'è¡›', 'ç”º', 'É•', 'ãƒƒ', 'ã‚´', 'è–¬', 'ï¾‰', 'Ä±', 'ç‰ˆ', 'ã‚¯', 'é»„', 'ÉŸ', 'Ã¡', 'Ï»', 'è¨', 'é ­', 'Ä¼', 'åˆ', 'Ã¼', 'ã‚', 'éƒ¨', 'â²§', 'ç•Œ', 'ãƒ‘', 'á¹£', 'ëˆˆ', 'é©š', 'ç‰©', 'à²¨', 'à¦Ÿ', 'è¿‡', 'Ï', 'çš„', 'ì„œ', 'â¿', 'Å³', 'Ç', 'à¸²', 'à»„', 'èŠ¦', 'É¾', 'É“', 'à¶»', 'Éœ', 'ê³µ', 'Ê”', 'çŒ«', 'à¤', 'å…¬', 'à®©', '×¨', 'Ë‘', 'é ', 'É', 'à´®', 'ã‹', 'å‹', 'Î®', 'é§…', 'è¬š', 'â†„', 'á¸·', 'ä½†', 'æ‘', 'Ã¹', 'ãƒ¡', 'ç¾', 'è»', 'ç¨¿', 'Âº', 'Å±', 'é’¾', 'à¸•', 'ê°•', 'ì¹¨', 'Ã°', 'Í¼', 'Å«', '×•', 'ã£', 'ã‚ª', 'áº½', 'çµ¡', 'Ñ—', 'É¿', 'ã‚’', 'å ', 'iÌ‡', 'é›', 'à¤·', 'èªª', 'ãƒ£', 'àº', 'ç”²', 'á´¬', '×“', 'è¨˜', 'áƒœ', 'Ä«', 'à®¤', 'ì°œ', 'è¬', 'ë²ˆ', 'å—', 'ï½¨', 'Ğ¿', 'ä¹ˆ', 'ê¸°', 'ãƒ¥', 'è¨³', 'İ£', 'æ‰¿', 'Ç˜', 'å®¶', 'ä»–', 'ã‚°', '×˜', 'æ´²', 'à¤¹', 'å¢“', 'ç‰', 'ç´”', 'Ø¹', 'å·', 'å‚³', 'á»‰', 'á½°', 'åŠ´', 'ã‚‹', 'å', 'å†', 'å…§', 'é—˜', 'Å“', 'åŠ‡', 'Õ´', 'å»', 'åŒ—', 'å¹´', 'é™¢', 'æ“', 'æ”¿', 'Ù…', 'è¿·', 'æ‰‹', 'æ»¡', 'á¼ ', 'Ø³', 'ã‚‚', 'Ê¾', 'Êœ', 'Ê°', 'é®®', 'ÏŸ', 'ã‚ƒ', 'æ‹‰', 'Ğ³', '×¡', 'à¸£', 'è¡Œ', 'à»œ', 'æƒ…', 'æ ¡', 'å·²', 'á¸¥', 'È‹', 'ã„', 'á½€', 'æ', 'á¸¡', 'Ä­', 'ã¡', 'å±±', 'æœ€', 'É”', 'ì¹ ', 'Ø®', 'å‰', 'ì²­', 'è‡¼', 'ã©', 'ã', 'å†’', 'å§»', 'İŸ', 'á½¶', '×™', 'Ù‚', 'ãƒš', 'á›Ÿ', 'ä¸–', 'Ë¡', 'æ’', 'ëŒ€', 'æ¡œ', 'Ã¿', 'åˆ', 'å•¼', 'á¹—', 'ï½”', 'é€™', 'å–·', 'É›', 'Ğµ', 'ç¼', 'åœ¨', 'æµ·', 'É£', 'æ˜¯', 'Ø¢', 'Ïƒ', 'áƒ—', 'Ê¡', 'Ñ‘', 'b', 'é†«', 'å€’', 'è‘¦', 'æ•…', 'ãƒ¼', 'à®¯', 'ã¯', 'å…±', 'æ¢', '×§', 'ç·¨', 'æ´»', 'ã¿', 'è˜­', 'äº¬', 'å¾¡', 'Ã­', 'ç†Š', 'àº¡', 'Ñ‰', 'ã°', 'ì•¼', 'æ»¬', 'Ğ²', '×›', 'ç«™', 'ç™½', 'í˜¸', 'á¹ƒ', 'çµ±', 'ï½ƒ', 'æ”¹', 'ã‚»', 'å¾Œ', 'å‡º', 'Ê™', 'Ù„', 'Ò‘', 'æµ', 'æŠ•', 'İœ', 'è¢', 'å’¨', 'è¦–', 'ÙŠ', 'è€Œ', 'á»‡', 'å', 'Øª', 'æ…•', 'çµ‚', 'å±‹', 'èŒƒ', 'ã‚¶', 'ç›Š', 'Îº', 'ğŒ²', 'â„“', 'ë‹¤', 'Ã¢', 'ãƒ—', 'É¬', 'ç‰¹', 'ç½‘', 'Î¹', 'æ–¹', 'á¸', 'ãµ', 'Ã£', 'ã˜', 'æœ', 'Úˆ', 'Ü£', 'Ï', 'Ñ†', 'ã“', 'è¬›', 'Í³', 'ä¿‚', 'ë¹ ', 'áƒ”', 'ì´', 'æ—©', 'Ã²', 'ê°œ', 'á¼”', 'Ëˆ', 'Õ·', 'È³', 'ï½±', 'å•†', 'ä¸»', 'ë§ˆ', 'àº™', 'ï½‹', 'á¿ƒ', 'é³´', 'á¼¡', 'ç”¨', 'æŸœ', 'à¤¥', 'ë§›', 'É«', 'å‰¯', 'à¸¢', 'è© ', 'Ğ°', 'è›‹', 'èˆª', 'å°ˆ', 'Ä·', 'ãƒª', 'è‡§', 'É™', 'à¸¥', 'æ—', 'Ä›', 'à»', 'ã', 'ã²', 'áƒ¦', 'ç”Ÿ', 'ã‘', 'à¨°', 'Ê›', 'à²¦', '×’', 'â„±', 'à¤–', 'è¡¨', 'ä¸œ', 'Í±', 'à¤”', 'æ¸ˆ', 'ÑŠ', 'àª¦', 'ç¹”', 'ç²µ', 'å·', 'ä¾†', 'Ê', 'æ–‡', 'éŒ²', 'ç‚º', 'áº«', 'Úœ', 'éƒ½', 'çƒ', 'è¢«', 'áš¹', 'ã”', 'ã„§', 'á½º', 'â…', 'á½„', 'å¥', 'áš', 'çŸ³', 'æ„', 'å¤–', 'à¤¡', 'Ï‚', 'Îµ', 'ã', 'é£', 'Ğ¶', 'Ñ', 'ãƒ ', 'Ø«', '×–', 'ä»€', 'ç·£', 'à°…', 'ì§', 'æ–­', 'á´·', 'æ¸…', 'Î¿', 'Ú†', 'ãƒ¯', 'çµ„', 'ã‚½', 'ç¬‘', 'æ’°', 'Ã«', 'å·±', 'çŒ›', 'İ“', 'ì˜', 'ãƒ•', 'á»©', 'èª¿', 'å™¨', 'Ğ¸', 'Ï‡', 'ã‚ˆ', 'à¨¨', 'Ë€', 'á¹›', 'æ†²', 'Ï…', 'ã‚³', 'á¹¯', 'à´µ', 'Ø¬', 'c', 'ç‘š', 'æº–', 'ì§‘', 'å‹•', 'éŠ€', 'æ´›', 'ç¨', 'Ù', 'Ñ’', 'Ø²', 'å¥½', 'Î¯', 'ãƒ§', 'áº£', 'åŒ…', 'æ³•', 'È™', 'É­', 'ã»', 'Ï‰', 'å®¹', 'Ä‹', 'Å—', 'Å•', 'ä¸ˆ', 'ê³ ', 'É°', 'åŸº', 'å®š', 't', 'è‹¥', 'ç¶™', 'ç•ª', 'à¦…', 'ç›’', 'É²', 'Ã¬', 'Ä…', 'Ø­', 'é¢¨', 'Å¯', 'ç„‰', 'ãƒ˜', 'äº†', 'áµƒ', 'áº¹', 'Ã¨', 'ç ‚', 'å­—', 'Ñ•', 'Ä£', 'ÊŒ', 'í˜ˆ', 'Çœ', 'è³œ', 'Å‚', 'É»', 'Ã¯', 'å°±', 'è¯‘', 'æ¼”', 'Î½', 'é€ ', 'ã—', 'á€', 'É’', 'å¿—', 'Ã ', 'Ê', 'Ç£', 'Ã´', 'Éš', 'é™ˆ', 'á»£', 'æ ¼', 'ï½', 'æ–¼', 'é»ƒ', 'é…¸', 'æŠ—', 'ç­†', 'ï½·', 'èŠœ', 'Ë', '×”', 'ã™', 'â²Ÿ', 'çŠ', 'ãŒ', 'áµ®', 'é›ª', 'Ø±', 'áº¯', 'ã‚…', 'êµ¬', 'æœŸ', 'q', 'Ç½', 'å³', 'è¨£', 'æŒ‡', 'å±Œ', 'Ï', 'ã³', 'Å', 'é«”', 'à°µ', 'à¤¤', 'Ñ‡', 'É¡', 'å·¾', 'Ø°', 'ãƒ’', 'Ã½', 'å§“', 'ë„˜', 'Å†', 'Åˆ', 'ë¹„', 'ç«', 'èª', 'Ä“', 'å’Œ', 'à¦¸', 'è‚¥', 'é€£', 'ç‰›', 'ã‚', 'à¸', 'á½²', 'ã¤', 'à¥', 'Ñ˜', 'áƒ¡', 'è‡­', 'Å¼', 'Ñ„', 'àª…', 'Ã¤', 'ÑŸ', 'ã‚­', 'ì†Œ', 'æ¿¤', 'å¤©', 'à¦¤', 'ç£', 'å„€', 'ä¼', 'è¿', 'Âª', 'àªµ', 'Ç', 'ãƒ›', 'á»‹', 'Ê•', 'á¹…', 'äºŒ', 'æ¿Ÿ', 'ìˆ', 'à¤ª', 'ãˆ', 'åƒ‘', 'ä»£', 'ä¹', 'á»™', 'è—©', '×—', 'à¦²', '×‘', 'å¡', 'ãƒ®', 'Õ©', 'Å›', 'ç«œ', 'áƒ®', 'à®œ', 'è·¯', 'í‹€', 'Ä‡', 'à¦¦', 'å°', 'Ø¡', 'é•¿', 'Ë ', 'ï½', 'ç¦', 'è¼', 'ç£', 'à¦°', 'Å¿', 'á¿†', 'à¤¶', 'Ç', 'ÇŒ', 'Õ«', 'è¯', 'æµ¦', 'à¨®', 'à¦‡', 'ä¸‹', 'ç‰', 'à®£', 'â„', 'æœ‰', 'Ù‡', 'o', 'ãª', 'Å£', 'à¤¨', 'á½…', 'Õ¸', 'å¼ ', 'ç¿', 'æ™®', 'Ñ§', 'É ', 'å‹™', 'Ä—', 'å®¢', 'ã‚¹', 'å†…', 'àº•', 'â„š', 'Ê‚', 'æ²–', 'ãƒ', 'ç™¾', 'á¼€', 'ãƒŠ', 'ç«¹', 'á›‡', 'ë¯¼', 'Ãª', 'á»«', 'è‰', 'å› ', 'å®˜', 'à¦•', 'ãƒ½', 'ë‚ ', 'ç¶­', 'à²…', 'ì¡', '×¦', 'r', 'ä»™', 'Ä¡', 'á¿³', 'p', 'ÊŸ', 'Å·', 'åœ°', 'è¼¯', 'å ´', 'åœŸ', 'à¤¦', 'å‹', 'ä»¤', 'Ä', 'È›', 'å¥³', 'çˆ½', 'ç¾', 'åº¦', 'É®', 'ã¾', 'ç«‹', 'å²', 'à®²', 'æƒ‘', 'ÅŸ', 'ä¸‡', 'à®†', 'â²±', 'æ¢¨', 'ìˆœ', 'äº', 'ã‚‰', 'è¯', 'à¤«', 'àº—', 'á»¥', 'Ç«', 'é”', 'Î¬', 'Ø¨', 'Ê', 'ì', 'Ö‚', 'æœª', 'å', 'à¤†', 'å¯', 'êµ°', 'å°‘', 'å¸', 'åˆ—', 'æ™¯', 'ã‚‡', 'è®°', 'éº—', 'ã‚±', 'Ğ¹', 'æˆ–', 'è¶', 'É', 'g', 'è–©', 'á‹­', 'Ä™', 'Ê§', 'éœ€', 'çª£', 'á¸Ÿ', 'æ™‚', 'Ê¿', 'à¶š', 'å¯¾', 'äº•', 'é¡Œ', 'à®‰', 'É¯', 'é¢', 'à¦œ', 'àº›', 'ä¸­', 'á¶', 'Ùˆ', 'ç›®', 'É˜', 'ËŒ', 'à¤®', 'å¯¹', 'ã¦', 'ì²«', 'Åµ', 'æ±‚', 'É©', 'e', '×¢', 'í—Œ', 'ï½—', 'à¤ ', 'áƒ¤', 'å¦ˆ', 'àºª', 'å­', 'æ¯', 'Î±', 'é˜¿', 'à¹', 'à¤¯', 'ä¸', 'àº„', '×¥', 'ãƒ¬', 'ê¸¸', 'èµ·', 'Å‘', 'ãƒ‹', 'Ø·', 'á›', 'ï½', 'Ñˆ', 'è´', 'ÊŠ', 'ãƒ“', 'Å¡', 'á¿–', 'â²©', 'à¦¨', 'è€…', 'è‹±', 'é™', 'à®š', 'Ø£', 'á¼', 'Ãµ', 'Ñ€', 'ç™»', 'æ€', 'è¡€', 'æ™º', 'æ²³', 'ï¾', 'à®µ', '×©', 'ç¥', 'Ñ', 'Ø¦', 'ì£¼', 'á‰µ', 'åˆ¶', 'æœ¬', 'ä½“', 'á»¯', 'à¸­', 'å¥', 'áº¿', 'é¾œ', 'å…«', 'Çƒ', 'ï¾ƒ', 'çœŒ', 'å¿ƒ', 'ã‚„', 'å£¹', 'å¸‚', 'áƒ•', 'a', 'Ã©', 'Êˆ', 'Ù†', 'å¾ˆ', 'åœ‹', 'ìœ ', 'å—', 'æ¾„', 'Ã¥', 'á»…', 'à¶³', 'é€€', 'Ê', 'ç´«', 'Å¾', 'å‘½', 'Äµ', 'à¤œ', 'Ã¸', 'İ—', 'æ“²', 'Ê„', 'Å€', 'ëŠ”', 'á”', 'ì²™', 'æ°¸', 'ä¿¡', 'æœ', 'Ç', 'Ó©', 'æ—¢', 'ã‚¸', 'áº­', 'ç·š', 'â„³', 'æ´', 'è£½', 'ã–', 'ç¿¼', 'ä»Š', 'É¹', 'Ğ¾', 'åŠ ', 'é€š', 'ë‰´', 'Ä', 'ï¾Ÿ', 'Ê»', 'Ã¾', 'å¯¦', 'á¸¹', 'ç¸„', 'àº”', 'Ï„', 'Ä•', 'á¹«', 'çŸ¥', 'æ€»', 'ä¾¿', 'é™º', 'v', 'è’™', 'Æ°', 'Ç°', 'É±', 'ÏŒ', 'Ï›', 'á½§', 'É¦', 'É¥', 'å³¶', 'à¤­', 'åœ', 'ã‚µ', 'à¦®', 'Õ¿', 'à¦¯', 'à®™', 'Ñ–', 'ã‚', 'à¤²', 'é¯', 'ì¡°', 'ç”°', 'à¤¸', 'à²µ', 'å®‰', 'è—', 'ì„ ', 'å»£', 'ç¸£', 'Ñ…', 'à¸›', 'É¤', 'ä¸¦', 'ç§‘', 'ãƒ«', 'å', 'é–©', 'ìš”', 'è¡“', 'ç»', 'ğŒ´', 'æ–°', 'Æ­', 'Ùƒ', 'ê²½', 'á¸»', 'k', 'çœ', 'ğŒ¿', 'é›»', 'ç¾Š', 'è¼¸', 'Ñ›', 'æ —', 'æ­¡', 'ä»˜', 'å¤‰', 'é‡‘', 'Ë‰', 'é˜²', 'æœ±', 'Ã³', 'Ã®', 'é›²', 'ãƒ´', 'áº·', 'x', 'åª', 'Õ³', 'éŸ¦', 'ãƒ”', 'åˆ©', 'Ú¯', 'à®•', 'Ç–', 'Õ¶', 'æ´ª', 'å£°', 'Ö€', 'ë¦¬', 'å“', 'ã‚¨', 'ç£¨', 'æ‚¨', 'åºœ', 'ã‚¡', 'Ê‰', 'ã„‰', 'Ø¤', 'åŠ©', 'à´Ÿ', 'å›½', 'æ­¦', 'çŠ¬', 'i', 'åš', 'åƒ', 'Ó', 'ÛŒ', 'Ú°', 'Å­', 'à¤¬', 'ãƒŒ', 'ãƒ©', 'áº§', 'Ğº', 'æ³›', 'ã‚«', 'å…¼', 'ë£¡', 'Åº', 'ç–‹', 'ë°›', 'à¦¬', 'æ±', 'Ğ´', 'â„', 'à¸§', 'á½¸', 'á»ƒ', 'ã‚¿', 'ç´…', 'è‡º', 'Ê¨', 'é’', 'Ñ‚', 'é›–', 'æ¸¡', 'é™³', 'æ¡”', 'é•·', 'Å©', 'ç¨±', 'æ°´', 'è–', 'æ¹–', 'ç–†', 'ã‚“', 'à¤—', 'ãƒˆ', 'Ğ»', 'æ±Ÿ', 'à·€', 'ãŸ', 'å', 'áƒ', 'áƒš', 'ã­', 'Ãº', 'é¾±', 'ç¿»', 'åŒº', 'æ¶›', 'ã‚', 'ã……', 'åŸ·', 'à¦¹', 'Ü', 'ë¬¸', 'ä¸€', 'ì¸', 'í¸', 'ç‰¡', 'àº¥', 'æ¬¡', 'ç´ ', 'å…µ', 'ã‚¢', 'Ê¢', 'à² ', 'æ…§', 'ã•', 'æ„Ÿ', 'à¸„', 'Ò', 'à¨–', 'Ğ±', 'è¯', 'ç­', 'Î¶', 'æ¥Š', 'Ã¶', 'ì•„', 'è¶Š', 'ã‚£', 'ãƒ', 'ä¾‹', 'ì•ˆ', 'áƒ·', 'Ê²', '×š', 'ì—­', 'å…ˆ', 'ÄŸ', 'ç²¿', 'Ã¦', 'è‰¯', 'ï½Œ', 'Ò›', 'Û»', 'Ú©', 'àºˆ', 'éƒ­', 'æ±‰', 'Õ¡', 'ã®', 'à°¨', 'á¹', 'â±·', 'è¨ª', 'à¤‹', 'Ç’', 'è±', 'ä¸Š', 'á¿·', 'Ñ', 'Ø´', 'ã‚¦', 'Ñœ', 'Ñ“', 'à¨œ', 'ãƒ¢', 'áµ', 'è¿‘', 'á»', 'å­¦', 'f', 'åˆ°', 'äº‹', 'Û', 'à¤‰', 'ğŒ¹', 'ï¾', 'Î­', 'åƒ', 'ã„', 'Å‹', 'áµ€', 'Ä', 'Î»', 'à¤µ', 'å››', 'éƒ', 'Ñ”', 'Ä¯', 'á¾³', 'è©±', 'Å§', 'å¤§', 'å¯§', 'Æ’', '×Ÿ', 'Ç§', 'æ›¹', 'ÃŸ', 'å°', 'åŠ‰', 'ã', 'ãƒ†', 'á¼´', 'à®…', 'È—', 'æŠ˜', 'ã„·', 'ãœ', 'Ø§', 'ä»¥', 'à¸¡', 'Ñ™', 'é¦¬', 'Ø¥', 'Ï†', 'ç„¶', 'Å', 'á¼°', 'Î´', 'ï¬‚', 'u', 'Ó§', 'çƒ‚', 'É´', 'á»', 'Äº', 'àª¨', 'æ—¥', 'É¸', 'å³', 'à¤Ÿ', 'á´¥', 'á»', 'Ê‘', 'à´¸', 'ë„', 'Î²', '×¤', 'æ­¥', 'é¡µ', 'è¾º', 'É§', 'á´€', 'ë³´', 'à®¨', '×', 'é¢ˆ', 'Ä¥', 'Ø¯', 'áµ—', 'ä»®', 'Üª', 'æ', 'ä½¿', 'Øµ', 'æ¥©', 'áƒ›', 'à®±', 'å²©', 'á¾¶', 'Éº', 'ä½©', 'à¤°', 'ãƒ‡', 'æˆ', 'è²¢', 'àº', 'ç¾©', 'èˆ¹', 'å¡©', 'Ä§', 'å€‘', 'Õ£', 'æºª', 'áƒ', 'áƒ’', 'æ¾', 'áƒ˜', 'æ’ƒ', 'è«–', 'éœ', 'á»¹', 'Ğ½', 'é¸', 'æ²¹', 'áƒ ', 'Ï', 'ã‚Œ', 'å¹³', 'Âµ', 'Ñ‹', 'ä½', 'ã…‚', 'ãƒ', 'Ğ·', 'à´•', 'à®´', 'áµ½', 'É³', 'ç…§', 'è™', 'éš»', 'à´¦', 'æ³¥', 'à®ª', 'ç€¾', 'àº°', 'æ—­', 'Äƒ', 'ì§€', 'á½¼', 'Å¥', 'É¶', 'Õµ', 'É–', 'É¢', 'ä¸‰', 'å­¸', 'æ³¨', 'Æ¡', 'á‹', 'Î·', 'å‘³', 'ä¼š', 'æ°', 'é‚ˆ', 'å°»', 'ä»‹', 'ç¥', 'æ˜', 'å¸ƒ', 'Å™', 'è±†', 'àº§', 'à®³', 'Î¸', 'á¹‡', 'É—', 'ãƒ', 'à»‚', 'à®®', 'n', 'Éµ', 'Ø¶', 'æˆ¸', 'É¨', '×', 'å•', 'åº„', 'ç½®', 'ãƒ„', 'åŠ', 'ã›', 'å…¸', 'Ê˜', 'å‰', 'ã’', 'Ä', 'àº£', 'åŒ', 'à¤§', 'Ã»', 'Ä‘', 'ë•Œ', 'á¿¦', 'àºŠ', 'É½', 'å', 'á¼‘', 'ï½³', 'á»±', 'à°¦', 'å®ˆ', 'ãƒ‰', 'à¨¸', 'àº«', 'àº­', 'Ê’', 'á¹™', 'ç´™', 'è¦‹', 'é‡', 'Ñ', 'ä¹Ÿ', 'Ä©', 'Ù‰', 'å·', 'è€', 'Ê‡', 'ã«', 'åˆ€', 'å¿«', 'æ”»', 'ä¸ƒ', 'å¨', 'Ñ', 'åƒ', 'à´°', 'Ë', 'İ¡', 'æ²ª', 'á¹§', 'æŸ³', 'é¾', 'à¤š', 'å¤œ', 'Ğ¼', 'å½±', 'à¨«', '×œ', 'Úµ', 'm', 'æ­¢', 'æœˆ', 'è‡ª', 'é€†', 'ìƒ', 'åˆ¥', 'ç©£', 'å¿', 'è·', 'ãƒ', 'Ï¸', 'á´¸', 'àº®', 'à¤•', 'áº¡', 'ãƒ™', 'å†™', 'j', 'ã„¨', 'á¼±', 'Ú¬', 'é¡§', 'à¤‡', 'Ä‰', '×ª', 'é™¸', 'ì²œ', 'Ê', 'Î³', 'Ï€', 'á»­', 'é™½', 'Ç€', 'ã‚¬', 'ã‚§', 'Ê'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dS4HiYpL0r6j"
      },
      "source": [
        "The words have 2335 unique characters, and there are characters (alphabets) other than those in english language. So the dataset also contains comment from other languages. In fact there are 1542 unique alphabets (26*2 from english and from other languages)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6lfR0voxVON",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05584607-a1fd-46a7-d680-bf85807a6067"
      },
      "source": [
        "languages = set()\n",
        "def calc_range(c):\n",
        "  if not c.isalpha():\n",
        "    return None\n",
        "  i = ord(c)\n",
        "  s = i\n",
        "  e = i\n",
        "  while chr(s).isalpha():\n",
        "    s -= 1\n",
        "  while chr(e).isalpha():\n",
        "    e += 1\n",
        "  return (s+1,e-1)\n",
        "\n",
        "for c in alphabets:\n",
        "  r = calc_range(c.lower()[0])\n",
        "  if r and r not in languages:\n",
        "    languages.add(r)\n",
        "\n",
        "print(len(languages))\n",
        "print(languages)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "107\n",
            "{(3754, 3755), (8160, 8172), (2579, 2600), (4824, 4880), (12549, 12591), (2308, 2361), (2979, 2980), (8319, 8319), (3804, 3807), (1786, 1788), (3751, 3751), (8134, 8140), (2741, 2745), (3253, 3257), (1649, 1747), (4808, 4822), (3507, 3515), (3114, 3129), (1568, 1610), (11360, 11492), (8579, 8580), (8178, 8180), (1808, 1808), (931, 1013), (3482, 3505), (3716, 3716), (2984, 2986), (8118, 8124), (1376, 1416), (4704, 4744), (3745, 3747), (97, 122), (73728, 74649), (6016, 6067), (8458, 8467), (1869, 1957), (3634, 3635), (2962, 2965), (66349, 66368), (2486, 2489), (3732, 3735), (2949, 2954), (3722, 3722), (1810, 1839), (2602, 2608), (890, 893), (3346, 3386), (3648, 3654), (3520, 3526), (736, 740), (1488, 1514), (181, 181), (186, 186), (12449, 12538), (3737, 3743), (3585, 3632), (2693, 2701), (2974, 2975), (5792, 5866), (2451, 2472), (2707, 2728), (8031, 8061), (3757, 3760), (1162, 1327), (2969, 2970), (7968, 8005), (4304, 4346), (880, 884), (8526, 8526), (8182, 8188), (2482, 2482), (8473, 8477), (65382, 65470), (12593, 12686), (2958, 2960), (170, 170), (8064, 8116), (2972, 2972), (64256, 64262), (216, 246), (44032, 55203), (3719, 3720), (12540, 12543), (2384, 2384), (8495, 8505), (65345, 65370), (710, 721), (3713, 3714), (12353, 12438), (7680, 7957), (8150, 8155), (2990, 3001), (3077, 3084), (2437, 2444), (3205, 3212), (2616, 2617), (1015, 1153), (3776, 3780), (19968, 40943), (3090, 3112), (3762, 3763), (7424, 7615), (248, 705), (3749, 3749), (2474, 2480), (3218, 3240), (8130, 8132)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBMlM5_L0jCs"
      },
      "source": [
        "There seems to be comments in 107 different languages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWkG4HUXs_93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "054a1747-d721-4221-f88c-f0d7c6f62cb4"
      },
      "source": [
        "print(len(links))\n",
        "links[:4]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4759\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<re.Match object; span=(275, 349), match='http://www.its.caltech.edu/~atomic/snowcrystals/m>,\n",
              " <re.Match object; span=(760, 826), match='http://digg.com/music/Wikipedia_has_free_classica>,\n",
              " <re.Match object; span=(1101, 1161), match='http://www.constitution.ie/reports/Constitutionof>,\n",
              " <re.Match object; span=(365, 395), match='https://ml.wikipedia.org/wiki/'>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiWaaNVgjVZD"
      },
      "source": [
        "there are links also"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1gCCAs2kC5L"
      },
      "source": [
        "# Preprocessing the data\n",
        "* Data preprocessing is an important step in Natural Language Processing. This helps to improve the model's accuracy and also reduces the training time.\n",
        "\n",
        "**What can we do?**\n",
        "* First thing we notice is that the case of letters doesn't change the meaning of the word and thus doesn't affect the toxicity level. (One might day that someting writting in all capital case has a stronger feeling, but does that help in classifying?\n",
        "```\n",
        "  Hi thErE How are yoU\n",
        "= hi there how are you \n",
        "```\n",
        "* Does the characters other than alphabets (in all languages) affect the toxicity? People tend to write certain \"toxic\" words by replacing some characters with the puncuation sumbols (*,@,...). Also certain puntuaion has some kind of emotion attached to them (!,...). Emojis have their own meaning. WE IGNORE ALLOF THESE to simplify our model.\n",
        "```\n",
        "only use c.isalpha()\n",
        "```\n",
        "* We replace the space characers `[\\t\\r\\n ]` and it's multiple occurence with a single space `' '`.\n",
        "* There are certain words that appears frequently in all the languages and are not that helpful for training the models. These are called **stop words**. To calculate the stop words, we use the count of all unique words and remove top 10 words from each language\n",
        "```\n",
        "we the i me am ... \n",
        "à¤®à¥ˆà¤‚ à¤¹à¥‚à¤ ...\n",
        "``` \n",
        "* We remove the links"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_y-qh3ejS7j"
      },
      "source": [
        "def preprocess(document):\n",
        "  doc = document.str.lower()\n",
        "  doc = doc.str.replace('[\\n\\r\\t ]+',' ')\n",
        "  doc = doc.str.replace('[^ï½¨ï½Õ³Ê’Ä§æ°‘Ï†å¸ƒç¥–ìà¸•åˆ¶Å¾×˜çŸ¥Úˆä¿¡hàºá›Ÿà®±Ë€æ¾„é uç»ì²«ç©£æ—©Î¿á¾³aá½„é’ã‚¯ä½ ã‚æŒ‡Äé™³å²©Ä¼äº¬Ã¨É™á‹­à¹ç”ºİ¡Ê§æ²¹è¦å¤œì¸ášì§€Î¸Å‹à¨¸ã¸ë…áƒ fä¸–Ã´ë§›ì¡°å‰çŠ¬è©±è‰¯áƒ·á»‰â²ŸÎ­Ã½ã‚¶å¥½Î½ï½ì„œæ°èª¿ç•ªãƒŒà¤¤à°¦ã˜è£½ÊŸç«¹×•Ê‹á¸ê³µå•¼ç¥éœç‹Ë¤åŠ´é¡¹ëˆˆáº§ë¬¸é¸åŠÎ¾ãƒšå†’è¶Šé–©êµ¬ç´”Ê°çƒ‚æ’Ã¤á¸·æ“àª¨ç«‹Ä¡Ù‡å—æ¿¤ã‚¦æ™‚ç…§æˆ‘è¿·Ñ‰Ä—áº£ã„·åå‘³ğŒ²ã†åˆáº“É¬ã®à²µæ–¼ä»Šá½¼Ü£é•¿è·¯é©šæ¬¡æºªĞ±É¾æ’°ï½·Ã¹ÅÉ¶éƒÎ¹ï½Œà¦¹ì•ˆé»ƒäºæ”»å‹ä½åŸãƒ´ã‹æ³•Ë Å•à¤œï¬‚è¯è‡ªê¸¸Ë‰ãƒì—­å°è™á¾¶×”kï¾ã‚¡à¤”Ø·ãƒœà¤‹æ°´ç‰å­æ‘æ­¥á´¬Ëá¿·ç‰›ÅÊëŠ”áµ®à®´æœÊŠÉ¤à¦¤åŒ…æ³›ã£åœ‹Ó§ãƒë§ˆì²™Í¼å¸«Ëä¼àº§á½²á»£ê²½×¢è‡§Ê·É±ë„æŸ³è¿‘ÙˆÑ§áº­çŒ«è±ç´«ãƒ†ã……à´°éƒ¡è°·Î¬á»«ãƒ½å¯§Ø¨Ñ†å™¨ï¾ƒæ¸…á¹«æ±ºå¸‚å¯¦Å™ç¹”à®¤á»¯æ±‰è¬ç¿¼æœ¬ã Õ¸Ê¿à´µè¾ºã„§åˆ—èŠ¦Ñ‹×©å­—éš¨Å¿å¯ã‚“á¿–à´ŸÄ‡à¶³à¦ŸåŒå³¶æ­¡ì£¼ç­†è‘¦æ—¥à®µåˆ©ã‚°ÅˆÊ˜åŠ áº¯åœï¾Ÿà¶»çœãƒ¢æµè¥¿Ù…ËŒë‰´è’™á¿³á»©å½±ğ’³å•¥Çƒà´•Ã¸æ´ªoè°¢à¤°é‚ˆÈ™æ±‚è—©Å†çˆ½Ñ•×šàª¦æ¼”å¾¡ã‚§ç·¨Ø²Å›É²Ñ˜à®¨Å—ë¹ æ¯æ”¹æ°¸Ïˆä¸‡á»ƒeà¤¹Ï»à®Å±Ã©ÊáƒœÆ¡à¦…æ‹‰á»±ç²µê°œİ“Üà®°ãƒ ãšç£çŠáµè¨ªà¨®æ™®è»Æ°ãƒ•Ä“É£æ±Ÿá¹ƒâ„šå¼ à¤‰é§…È‹Ïå»£è‡­ÄµæŸ±Ê¢ãŒÉ¢nç¶™ã„é€†å’¨å±±Ğ³Çæ¥ŠÊ¾ç–†áƒ¦ì²œÄ‘ç£İ£Î·ç¼à¸éŸ¦è‡ºå³Êí˜¸ï½³ï½‹à¤Ÿá»‡à¤šàº‡è© æ”¿Ä¯ãµé™ˆçµ±éŒ²à»œà¦­å·å‹™Î¶Åè´åœ°å¥³à¤§åœ¨è¦‹é¢æ€»á¿ƒã‚‚ÊŒè¡¨àº¥Å“äº•Ó©Éãƒ’Ä‹æ³¥ã‚‰ãƒƒé‡‘ä¸à¦œìƒÑ„ä¹ŸÉ³æœ±æœŸÏ‚á¸¡å’Œá¿†â„±è¶æ‰‹æˆ¸æ¸¡æ´²çŒ›å£°åºœæ•…à®…å»È›æ´»ÒİŸà®œÑ›Ã¥Ã¢Î®ã‘Ñ€ã²å®˜ã‚¨é™¸Øªì•¼åƒ‘Ç§æ–‡ëŒ€çƒã‚·Ù„è¨˜åº¦à¨œà¥Äºà¦¯ä»€ã­Îºå¤–Å¥ãŸà¦¨Ğ¸ç€¾ä¸‹á¹í‹€Ñà¸¥Ãªmç‰¹ã¾ã°åé™Çšà¤¦å µã¹Ø³áƒ˜å¿—ç¦ãƒç”°Ã¼ã‚¤à®‰xÊÙƒç¿é¾œÂªá»‹ì§‘á¹™É½â„“è¡“ãƒ‘Ã¬Éæ´åªâ¿è¡€à®‡à·€è®°Û»ãƒ³ã¡Î±ğŒ´Ä·æŠ•å·ã‚æ’ƒÇ€è€…äº†Ê›áƒ’å›ê¸°ç«Ã±å·²É¿à²¦ç²¿â…Ï›æ…•Ã¿è®ºæ–°è¢«ãƒ¬çš„ì°œá¸¹Ï…å°ˆæ–­É—å¤§é¡ŒÕ¡ç„‰ä¸ƒå—è¬šèµ·è¯á»­ìŠ¹×ªçœŒÏ¸â†„áµƒåƒÉ­ä¸€í¸Å„å‰¯ãì¹¨ç¸„Å¼ä½©ä»®bç´ è—ãƒ£ØµÉ’Ëˆé¾ã„qà°…Ø¤×ã‚±ä½æ‹¬Î»é³´â±·à»„É å³ãƒ˜ã‚µæ²³è¿‡åº„á¸¥à¦°áº±áº·ã¤çµ¡èªáº½É¯è¯Ê²ã«ç‹¬å ´å®¹ãƒ©Ä¾é•·ç¥ç¿»ç›’é—˜ç‰ˆç”²ãƒ“á»¹à¦•ç†Šç¸£É¨ÛŒå“Õ£Ñˆê°•à¶­äº‹è¬›Ğ¾É°Ã¾é…¸Ç£å·Ã£à¤¶à¤¯æ²–à¸£ãà²¨Åµä¸»è¡ŒÊáƒ¤×›è‡¼à®£ç¾Šãƒåˆ€é˜¿æµ·è‰ç›Šã‚ªä¾†æ˜¯ÂµÜà² ç«™á½¶É¦à¤‡á¼¡å€‘å°‘êµ°æ†²Ø§ãƒ¥æº–á»ä¼šØ¬æ‰¿á¼‘ãƒé›–ç«œá»‘ä¸‰èˆ¹Õ¿è›‹å¤ªåé›ªì•„ãà¸›æ ¼Ã°É©ãƒ«í˜ˆç•Œè€ŒÃ¦Å¡àº®é™ºÏ€Ä£àº«á¹›Ø¸Ö€à®ªØ©æ•ç£¨å­¦ãƒŠá´¸è·ë‹¤è˜­ÑŸèŒƒÎ¼Ä›å…§ë°›é›ã”à¸­ç¶­×–æ¡œà¤²ì§àº¡ë•ŒæŸœÚ†å£¹Ïá¹§å¾ˆà»‚æ¿Ÿæ¥©ã‚’å‰ÊˆÊ”ÙŠå•ä»™Ê‘æœˆÈ³éƒ­à¸¡ãƒ—Ñ–ã‚­à®©ãƒ–å å†™è¨³àºŠÃ»Ñ‡ãƒ‰Ã§ã„‰à¦¦à®•å·¾ä¸Šà¤áš¹ã‚¬Ö‚ì²­ãƒ›ë³´ã‚£è–©Å€È—æ²ªà¦®ÉœİœÃ¡ã›zå¯¹Å«áº«å…«É•á¹…Ûå–·à¤«ç™¾é«˜å°±ç”¨Ï„àªµÓ£ã‚³è¿áƒ›á¼´áµ½ãƒ™é¢¨Ğ¹è‚¥á´·å·±æ»¡Ø£è‹±ÊÉ«wÎ²ãƒ„Ñ—å®¶é–¢å‹•å…µÊ‡æ“²å¿à®¯É§Ãºá»…åšçµ‚lá¸»éŠ€É¸å¥àº—áƒ•à¤—è–¬å››åŠ‰â„É˜×Ÿæ—­Ñã‚ˆ×“É®á¼±å¡©ãŠiÄ…è¼è¼¯ä¾¿Ñšà¦¸æ™¯èªÄŸè¼¸àº”æ´›è¢äººãƒ®à²…à¤¥á›ã„¤ÏæˆÕ·ìœ é€ Î¯sæ¼¢é¾±è²¢ë¹„áº¥à¤·à¸„ãƒ‡É“èƒœÉÚ©áƒšï¾‰à¤¡æ²»ë²ˆá¹£å­¸ä¹á¶ç”Ÿ×’éƒ¨è±†å®•É´Ñà¸§Å‘å¦ˆÑ”Å©ã‚´ç‰©ÏŒĞ¼åœŸå‘½ã•ç‰¡æ­¢å…ˆã§é¡µã»ã‚Œáƒ—â„³àº²Ú¯å•†áº¡ï½ƒã‚Šã—å¤ÂºÑ’Î³ç½‘á½§áµ—ä½†Ñœå±Œåˆ¥ã‚„æåà¤ªÄ‰ä½“èˆªà¨¨Ä«Ä©çŸ³Ê€Ø±é˜²åã™á¼ Æ­ç¨¿ãƒ‹Ğ´ã¬åŸ·ÕµÉšå®šÅ¯Ñ™æ¢¨ç™»Ùä»˜Ê¼áƒÊ‚Ø¶ã‚é†«å€’Éºàº„ä¸ªæœå¤©á¼°ğŒ¿Éªà¦¬å°»à¤¨Ñæ…§á¹—Ø¯ì„ Å§è¿™Ñƒå®¢ÅŸãƒã‚¸æŠ—å±‹æ„ŸyÇ°ÉµÚµà´®é›²ë ¤åˆâ²§á¹¯Ç’ì¹ É›á”è¡›Ä±Ü˜ç‚ºè³œé¹¿å›½è€ë‚ é›»Óà¤­æ—¢×§èŠœáƒå¹²é€€å¢“Ê‰Ú°×¦ç ‚Ù‚æµ¦ãƒ§ç¨×¥æ„é¯iÌ‡àº£Úœà¤µà¶šå¨áµ€é’¾â²±Ë¡Ï‰æ¸ˆé«”ÉŸå²àºï½—æ¢É”ì¡Ê„ÑŒàº›ç™½ä¸œÊ¡æ¾ìˆæœ‰ë„˜è«–Ê•áƒ”á½ºÉ¡Ñ‚Ø¡éš»á€ä»¤Õ«Ä­è¦–å¤‰å…¸å‹ê³ à¤£×¤è¨£Ï‡ä¾‹ÇŒá¿¦æƒ…ç„¶à¸²æ„›è¨€ÑŠç´…ç¨±tá´€ï½É–é¾™ä¹™Çä¸ˆÙ†á¹à¤¬Ê»á¼å¯¾Ø¢å¿ƒØ¹é¢ˆå°àº•Îµé ­ç·£æ»¬Ğ»æ‰€äºŒå¡×™àº­ã‚‹è–Ç‚Ğ¿ãƒ”ãƒªä¸¦è‹¥á¼”Ç–É¹×—ã‚«è¨Õ©à¤®à¦²å§“ï½±æ¶›Ê™Ù¾æœªåˆ°ç›®á‰µæ‚¨ãƒˆÚ¬×¨é™½ç·šÅºãƒ¼ãƒ­Ë‘Ø¥á´¥Å³Î´æ›¹é€™á¸Ÿìš”ä¹å¥Ò›é¡§å¹³á½…ç–‹æ˜Ç”æ›¸ç‘šé€£Ã®æà®™ã‚¿Ë¢â²©æ­¦æ —ä»‹åŒºããƒ¯æ±å› ÃŸå†…à¤¸ĞµĞ¶à´¦İ­ç†±æ¹–ï½Ø´åŒ—æ³¨ãˆä¹ˆç§‘æ™ºà¤•ä¸­å‚³æœ€á»ã‚®ë£¡å…±â„ä»¥ë¦¬cæ—á¹‡Ã¶ä¿‚Äå®ˆÃ Ã­×¡á¼€æƒ‘ã‚…ÄƒÒ‘Ç½í—Œà®’Ø°àºˆã‚‡é™¢Õ¶ç¬‘rğŒ¹áƒ¡Ñä½¿Å·ÇœÄ¥á‹å¿«é‡ã¨à´¸ãƒ¡Äá›‡×ã©áº¿æ€çª£ãÉ»à®²à®šã¦à¨°èªªã‚½jé€šé®®à¸¢á½‚Ã¯Ç«å„€à¤ æ–¹ã“å¹´æ¡”à¤–á»É‘é»„× åƒãœáº¹ä»£gÊ¨ã‚»àº™ï½”×œĞ½à°¨æ³¢à®Ÿà®®éœ€ã–Å£ë¯¼å¸à¤…ã„¨à¤˜àª…áƒ®Ã«Øºã‚¢pç‰Ğ·éº—ã³åƒæ ¡é‡Œç¾æ©˜Çå§»ÃµÃ³á½¸áƒà°µÅ­ã‚å—àºªÆ’à®³Ù‰Ø­å®‰Ñ‘Ä•ç¾©ç¾Êœæˆ–ä»–Ø®ìˆœç½®ç­à¨«ÏŸè¯‘ì†ŒæŠ˜á»™Ç˜Ø¦á»¥å‡ºĞ²á¿¶Üªé”çœŸà¦‡Ò¯×‘ğŒ°à»dã…‚ã¯å¾Œà®†ã‚ƒÃ²×å­«Êƒçµ„é¦¬éƒ½ã¿å…¬Í³åĞ°Í±Ïå…¼ãªÑ…ì´Õ´Å‚à¨–É¥Ğºá¹­ã’å²¡ì˜à¤†ã‚¹Ø«åŠ©Ïƒç´™é£ÊvÄï¾å†ÇåŠ‡àº°Ñ“åŸºİ—á½°Ä™á½€ ]','')\n",
        "  doc = doc.str.replace(\"[^a-z ]\", \" \")\n",
        "  doc = doc.str.replace('https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)', '')\n",
        "  return doc\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISbXMc04TVQi"
      },
      "source": [
        "clean_comment = preprocess(train_df[\"comment_text\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jgqs-NdW24Q2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "282b2b86-b062-4219-a95f-a6371f5544ba"
      },
      "source": [
        "word_count = {}\n",
        "for sentence in clean_comment:\n",
        "  unique = set(sentence.split(' '))\n",
        "  for word in unique:\n",
        "    if word not in word_count:\n",
        "      word_count[word] = 1\n",
        "    else:\n",
        "      word_count[word] += 1\n",
        "\n",
        "print(f\"There are {len(word_count)} unique words\")\n",
        "global languages"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 223520 unique words\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Igo2qqmtMNxL"
      },
      "source": [
        "top_sorted = [w for w in sorted(word_count.items(), key=lambda item: item[1], reverse=True)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ev4CLECmYEO9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11d819da-b932-4a56-c3b9-fb29920fd8b9"
      },
      "source": [
        "top_sorted[:4]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 106805), ('to', 94487), ('', 90700), ('a', 82193)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wmaTixFVsS3"
      },
      "source": [
        "These are the top 4 most occuring words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4TL3wl8M9fE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88468920-8ce6-42d6-d2c4-0bae191a4be4"
      },
      "source": [
        "languages = list(languages)\n",
        "languages.sort(key=lambda item: item[0], reverse=True)\n",
        "languages[:4]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(73728, 74649), (66349, 66368), (65382, 65470), (65345, 65370)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WelK4SWRXgXI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac57d20e-de86-4479-c40f-c92ab070e275"
      },
      "source": [
        "calc_range('a')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(97, 122)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plph3LRhXqnl"
      },
      "source": [
        "languages.remove((97,122))\n",
        "languages.append((97,122))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIcJkKYqOPVa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc1b8af7-ef40-4286-bd51-c14f1c5d2ca7"
      },
      "source": [
        "languages[::-1][:4]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(97, 122), (170, 170), (181, 181), (186, 186)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38HLrp7BPKvC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f08693a0-e9ff-45a6-c1f7-776707df85a3"
      },
      "source": [
        "chr(97),chr(122),chr(170),chr(170)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('a', 'z', 'Âª', 'Âª')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ocn5lcVCQVQJ"
      },
      "source": [
        "def in_lang(c):\n",
        "  i = ord(c)\n",
        "  for j,l in enumerate(languages):\n",
        "    if i>=l[0] and i<=l[1]:\n",
        "      return j\n",
        "  return None\n",
        "\n",
        "def is_different_lang(word):\n",
        "  min_i = 100000000\n",
        "  for c in word:\n",
        "    l = in_lang(c)\n",
        "    if l:\n",
        "      min_i = min(min_i, l)\n",
        "  if min_i != 100000000:\n",
        "    return min_i"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVPRV2LTNaVU"
      },
      "source": [
        "stop_words = []\n",
        "\n",
        "itr = iter(top_sorted)\n",
        "done = False\n",
        "i = 0\n",
        "try:\n",
        "  while not done:\n",
        "    i += 1\n",
        "    word,count = next(itr)\n",
        "    d = is_different_lang(word)\n",
        "    if d:\n",
        "      stop_words.append((word,count))\n",
        "      for _ in range(9):\n",
        "        i += 1\n",
        "        word,count = next(itr)\n",
        "        stop_words.append((word,count))\n",
        "      languages.pop(d)\n",
        "except:\n",
        "  done = True\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFEB9Uf-TGMM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b239c6e-eba4-4669-9090-be1e1b44c3f9"
      },
      "source": [
        "print(stop_words[:50])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('the', 106805), ('to', 94487), ('', 90700), ('a', 82193), ('and', 80264), ('i', 77145), ('of', 76376), ('you', 73144), ('is', 72625), ('that', 64508)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djrRC--nWjQw"
      },
      "source": [
        "These are the top 10 words with highest frequency in all the languages. But the frequence if too low for other languages, We'll stick to english stop words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1o9Jp_AXEfP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58bff01e-3e79-4138-dedc-259647fd57e0"
      },
      "source": [
        "print(top_sorted[:40])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('the', 106805), ('to', 94487), ('', 90700), ('a', 82193), ('and', 80264), ('i', 77145), ('of', 76376), ('you', 73144), ('is', 72625), ('that', 64508), ('it', 63305), ('in', 61911), ('for', 55290), ('this', 54359), ('not', 51715), ('on', 49233), ('be', 48600), ('have', 43139), ('as', 41217), ('are', 41097), ('if', 38102), ('with', 37877), ('but', 34971), ('your', 34311), ('or', 31883), ('article', 31477), ('was', 30655), ('an', 29656), ('from', 28690), ('my', 28080), ('do', 27822), ('at', 27651), ('page', 27468), ('by', 26725), ('so', 26699), ('about', 25566), ('can', 24852), ('me', 24820), ('what', 24523), ('there', 23193)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bInbgGpeXG6d"
      },
      "source": [
        "reg = r'\\b(?:{})\\b'.format('|'.join([x[0] for x in top_sorted[:40]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94A-gHlRYmTV"
      },
      "source": [
        "clean_comment = clean_comment.str.replace(reg,'')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yju6oESoZEVu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0483e419-a315-4ed3-923f-6f40b591d879"
      },
      "source": [
        "clean_comment[:4]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    explanation why  edits made under  username ha...\n",
              "1    daww he matches  background colour im seemingl...\n",
              "2    hey man im really  trying  edit war its just  ...\n",
              "3     more  cant make any real suggestions  improve...\n",
              "Name: comment_text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvjZfbmzexai"
      },
      "source": [
        "train_df[\"comment_text\"] = clean_comment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nXiwW_vZMCt"
      },
      "source": [
        "# ---------------Data Preprocessing Done-----------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69zg5-OQjbZw"
      },
      "source": [
        "# Train Cross Validation Split\n",
        "We use 80:20 ratio to split the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYvPZGpNnByZ"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pj6n0sOzsOx1"
      },
      "source": [
        "unique_words = train_df[\"comment_text\"].copy(deep=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqkZLCwNsryP"
      },
      "source": [
        "for i in range(unique_words.shape[0]):\n",
        "  unq = set(unique_words[i].split())\n",
        "  unique_words[i] = ' '.join(unq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNY7j0rymz7n"
      },
      "source": [
        "word_tfid = TfidfVectorizer()\n",
        "word_vec = CountVectorizer()\n",
        "word_vec_bin = CountVectorizer()\n",
        "word_tfid_f = word_tfid.fit_transform(train_df[\"comment_text\"])\n",
        "word_vec_f = word_vec.fit_transform(train_df[\"comment_text\"])\n",
        "word_vec_bin_f = word_vec_bin.fit_transform(unique_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59N9iKCdezU8"
      },
      "source": [
        "#train cross validation split\n",
        "def train_cv_split(col, cv_ratio):\n",
        "  zero_ind = []\n",
        "  one_ind = []\n",
        "  chk = train_df[col] == 1\n",
        "  for i,c in enumerate(chk):\n",
        "    if c:\n",
        "      one_ind.append(i)\n",
        "    else:\n",
        "      zero_ind.append(i)\n",
        "  np.random.seed(5)\n",
        "  np.random.shuffle(zero_ind)\n",
        "  np.random.shuffle(one_ind)\n",
        "  total = train_df.shape[0]\n",
        "  onen_v = int(len(one_ind) * cv_ratio)\n",
        "  zeron_v = int(len(zero_ind) * cv_ratio)\n",
        "  onen_t = len(one_ind) - onen_v\n",
        "  zeron_t = len(zero_ind) - zeron_v \n",
        "\n",
        "  train_ind = zero_ind[:zeron_t] + one_ind[:onen_t]\n",
        "  cv_ind = zero_ind[:zeron_v] + one_ind[:onen_v]\n",
        "\n",
        "  np.random.shuffle(train_ind)\n",
        "  np.random.shuffle(cv_ind)\n",
        "  return train_df.iloc[cv_ind,:],train_df.iloc[train_ind,:],word_tfid_f[cv_ind,:],word_tfid_f[train_ind,:],word_vec_f[cv_ind,:],word_vec_f[train_ind,:],word_vec_bin_f[cv_ind,:],word_vec_bin_f[train_ind,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hyd25_Uojf9A"
      },
      "source": [
        "dataset = {\n",
        "    \n",
        "}\n",
        "for col in cols:\n",
        "  dataset[col] = train_cv_split(col, 0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0siPMJFlj15w",
        "outputId": "fee070fe-fda3-4070-c9a7-f4135426cb5b"
      },
      "source": [
        "dataset[\"toxic\"][0].shape,dataset[\"toxic\"][1].shape,dataset[\"toxic\"][2].shape,dataset[\"toxic\"][3].shape,dataset[\"toxic\"][4].shape,dataset[\"toxic\"][5].shape,dataset[\"toxic\"][6].shape,dataset[\"toxic\"][7].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((127656, 8),\n",
              " (31915, 8),\n",
              " (127656, 223456),\n",
              " (31915, 223456),\n",
              " (127656, 223456),\n",
              " (31915, 223456),\n",
              " (127656, 223456),\n",
              " (31915, 223456))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkEx5UyKZP-1"
      },
      "source": [
        "# Logistic Regression\n",
        "We now train a Logistic Regression model. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHQoOP77b0Fc"
      },
      "source": [
        "### Data Representation\n",
        "Logistic Regression requires the data to be numeric. We need a way to convert the comments to numeric value.\n",
        "\n",
        "We convert the documents (list of comments) to tfâ€“idf form"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNnH5SXNbSCw"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TgkmSmzj_sn"
      },
      "source": [
        "train,cv,train_tf,cv_tf,train_vec,cv_vec,train_vec_bin,cv_vec_bin = dataset[\"toxic\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiihXb7XrlkB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6af28d33-8a1a-40e8-f6f6-00ede931850b"
      },
      "source": [
        "models = {}\n",
        "reg_const = [0.01,0.1,1,10,50,100]\n",
        "for col in cols:\n",
        "  print(col)\n",
        "  models[col] = {\n",
        "      \"tf\":[],\n",
        "      \"vec\":[]\n",
        "  }\n",
        "  for C in reg_const:\n",
        "    print(C)\n",
        "    models[col][\"tf\"].append(LogisticRegression(max_iter=5000,C=C))\n",
        "    models[col][\"tf\"][-1].fit(train_tf,train[col])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "toxic\n",
            "0.01\n",
            "0.1\n",
            "1\n",
            "10\n",
            "50\n",
            "100\n",
            "severe_toxic\n",
            "0.01\n",
            "0.1\n",
            "1\n",
            "10\n",
            "50\n",
            "100\n",
            "obscene\n",
            "0.01\n",
            "0.1\n",
            "1\n",
            "10\n",
            "50\n",
            "100\n",
            "threat\n",
            "0.01\n",
            "0.1\n",
            "1\n",
            "10\n",
            "50\n",
            "100\n",
            "insult\n",
            "0.01\n",
            "0.1\n",
            "1\n",
            "10\n",
            "50\n",
            "100\n",
            "identity_hate\n",
            "0.01\n",
            "0.1\n",
            "1\n",
            "10\n",
            "50\n",
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "e9Ju2Fc1Fgt0",
        "outputId": "f611392a-408e-414e-8483-f2d248d5121a"
      },
      "source": [
        "models = {}\n",
        "reg_const = [0.01,0.05,0.1,0.5,1,2,5,10,20,50,70,100]\n",
        "for col in cols:\n",
        "  models[col] = {\n",
        "      \"tf\":[],\n",
        "      \"vec\":[]\n",
        "  }\n",
        "  for C in reg_const:\n",
        "    models[col][\"tf\"].append(LogisticRegression(max_iter=5000,C=C))\n",
        "    models[col][\"tf\"][-1].fit(train_tf,train[col])\n",
        "    models[col][\"vec\"].append(LogisticRegression(max_iter=5000,C=C))\n",
        "    models[col][\"vec\"][-1].fit(train_vec,train[col])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-bfce4f7248c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tf\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_tf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"vec\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"vec\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_vec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1599\u001b[0m                       \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m                       sample_weight=sample_weight)\n\u001b[0;32m-> 1601\u001b[0;31m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[1;32m   1602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"L-BFGS-B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m                 \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"iprint\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0miprint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gtol\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"maxiter\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m             )\n\u001b[1;32m    938\u001b[0m             n_iter_i = _check_optimize_result(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m--> 610\u001b[0;31m                                 callback=callback, **options)\n\u001b[0m\u001b[1;32m    611\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_loss_and_grad\u001b[0;34m(w, X, y, alpha, sample_weight)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mz0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;31m# Case where we fit the intercept.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__matmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    562\u001b[0m             raise ValueError(\"Scalar operands are not allowed, \"\n\u001b[1;32m    563\u001b[0m                              \"use '*' instead\")\n\u001b[0;32m--> 564\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__mul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__rmatmul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;31m# Fast path for the most common case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m_mul_vector\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0;31m# csr_matvec or csc_matvec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sparsetools\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_matvec'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m         \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXBqwE0BXadV"
      },
      "source": [
        "clf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHEsRFM9dXEz"
      },
      "source": [
        "clf = LogisticRegression(max_iter=5000)\n",
        "clf.fit(train_tf,train[\"toxic\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lqcoan_7kNT_",
        "outputId": "21e8a9b7-39ac-46ba-a83d-543e2bfeb708"
      },
      "source": [
        "print(sum(clf.predict(train_tf)== train[\"toxic\"])/train.shape[0] * 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "96.16625932192768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbOlMsr6k0Zo",
        "outputId": "b05dca68-c2d6-42fe-efdd-333e15d03d03"
      },
      "source": [
        "print(sum(clf.predict(cv_tf)== cv[\"toxic\"])/cv.shape[0] * 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "96.08334638884537\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqUa4SGKoeIn"
      },
      "source": [
        "Train set accuracy = 95.98%\\\n",
        "Test set accuracy = 95.88%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0I1K8YuTlyQ3",
        "outputId": "e482fbf1-46e1-437b-cb30-11f144a4f958"
      },
      "source": [
        "clf = LogisticRegression(max_iter=5000)\n",
        "clf.fit(train_vec,train[\"toxic\"])\n",
        "print(sum(clf.predict(train_vec)== train[\"toxic\"])/train.shape[0] * 100)\n",
        "print(sum(clf.predict(cv_vec)== cv[\"toxic\"])/cv.shape[0] * 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "98.125430845397\n",
            "97.98527338242205\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVZrdqRXpPhO"
      },
      "source": [
        "Using count vector, instead of term frequency\\\n",
        "Train set accuracy = 98.07%\\\n",
        "Test set accuracy = 97.98%\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LguPYnDouYa9",
        "outputId": "7db29d95-37b2-4463-a0b1-97a67d5e124e"
      },
      "source": [
        "clf = LogisticRegression(max_iter=5000)\n",
        "clf.fit(train_vec_bin,train[\"toxic\"])\n",
        "print(sum(clf.predict(train_vec_bin)== train[\"toxic\"])/train.shape[0] * 100)\n",
        "print(sum(clf.predict(cv_vec_bin)== cv[\"toxic\"])/cv.shape[0] * 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "98.03691170019427\n",
            "97.92887357042144\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXXB-x-hueVq"
      },
      "source": [
        "Using count vector binar\n",
        "Train set accuracy = 98.03%\\\n",
        "Test set accuracy = 97.92%\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eo-loQBU2r-Y"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9OEwYKOr7I9"
      },
      "source": [
        "# Naive Bayes\n",
        "We now train a model using Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ABQIHmdsFfk"
      },
      "source": [
        "The comment is now represented as count vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKLYzcgusEvO"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2EHIG2Ks-X_"
      },
      "source": [
        "models_nb = {}\n",
        "alpha = [0.01,0.1,0.5,1]\n",
        "for col in cols:\n",
        "  models_nb[col] = {\n",
        "      \"tf\":[],\n",
        "      \"vec\":[]\n",
        "  }\n",
        "  for a in alpha:\n",
        "    print(a)\n",
        "    models_nb[col][\"tf\"].append(MultinomialNB(alpha=a))\n",
        "    models_nb[col][\"tf\"][-1].fit(train_tf,train[col])\n",
        "    models_nb[col][\"vec\"].append(MultinomialNB(alpha=a))\n",
        "    models_nb[col][\"vec\"][-1].fit(train_vec,train[col])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyUSKbgio39w",
        "outputId": "161ac419-c2b1-4cad-8032-8ffdf1b0b6c0"
      },
      "source": [
        "clf = MultinomialNB(alpha=0.01)\n",
        "clf.fit(train_vec,train[\"toxic\"])\n",
        "print(sum(clf.predict(train_vec)== train[\"toxic\"])/train.shape[0] * 100)\n",
        "print(sum(clf.predict(cv_vec)== cv[\"toxic\"])/cv.shape[0] * 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "97.0882684715172\n",
            "96.9732100892997\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6FH-r6fvQz7",
        "outputId": "3ade6bb2-ce65-4da5-f4d3-29c401fed089"
      },
      "source": [
        "clf = MultinomialNB(alpha=0.01)\n",
        "clf.fit(train_vec_bin,train[\"toxic\"])\n",
        "print(sum(clf.predict(train_vec_bin)== train[\"toxic\"])/train.shape[0] * 100)\n",
        "print(sum(clf.predict(cv_vec_bin)== cv[\"toxic\"])/cv.shape[0] * 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "96.1082910321489\n",
            "95.97054676484412\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OI9hRq4yvrSz"
      },
      "source": [
        "#Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgGUsey_vdwj"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "clf = LinearSVC(random_state=0,tol=1e-5)\n",
        "clf.fit(train_tf,train[\"toxic\"])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}